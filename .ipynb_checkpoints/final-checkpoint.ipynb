{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4f2938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tdmclient in c:\\users\\paul\\anaconda3\\lib\\site-packages (0.1.21)\n",
      "Requirement already satisfied: numpy in c:\\users\\paul\\anaconda3\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\paul\\anaconda3\\lib\\site-packages (1.15.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\paul\\anaconda3\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: tqdm in c:\\users\\paul\\anaconda3\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: websockets in c:\\users\\paul\\anaconda3\\lib\\site-packages (from tdmclient) (15.0.1)\n",
      "Requirement already satisfied: zeroconf in c:\\users\\paul\\anaconda3\\lib\\site-packages (from tdmclient) (0.147.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\paul\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: ifaddr>=0.1.7 in c:\\users\\paul\\anaconda3\\lib\\site-packages (from zeroconf->tdmclient) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tdmclient numpy scipy opencv-python tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec37acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import cv2\n",
    "import tqdm\n",
    "from Computer_vision import cv as com\n",
    "import Filtering as flt \n",
    "from Global_Nav import global_nav as gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95ae813b",
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtdmclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ClientAsync, aw\n\u001b[0;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m ClientAsync()\n\u001b[1;32m----> 4\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m client\u001b[38;5;241m.\u001b[39mwait_for_node()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m node\u001b[38;5;241m.\u001b[39mlock()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tdmclient\\clientasync.py:106\u001b[0m, in \u001b[0;36mClientAsync.wait_for_node\u001b[1;34m(self, timeout, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m     sleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEFAULT_SLEEP)\n\u001b[0;32m    105\u001b[0m     time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEFAULT_SLEEP\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[1;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initiate the communication between the Thymio and the computer\n",
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b801d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================HYPERPARAMETESRS======================\n",
    "\n",
    "#REAL SiZE OF THE ENVIRONEMENT (cm)\n",
    "L = 113.5\n",
    "W = 81.3\n",
    "Ratio = L/W\n",
    "\n",
    "#SiZE IN PIXEL OF THE CORRECTED MAP\n",
    "Y_res = 480\n",
    "SIZE = [Y_res, int(Y_res*Ratio)]\n",
    "\n",
    "#FILTERING PARAMETERS FOR THE ORIGINAL IMAGE\n",
    "B1_O = 10\n",
    "B2_O = 80\n",
    "B3_O = 80\n",
    "C1_O = 0.5\n",
    "C2_O = 1.5\n",
    "M1_O = 8\n",
    "CL1_O = 2.0\n",
    "\n",
    "#FILTERING PARAMETERS FOR THE CORRECTED IMAGE\n",
    "B1_C = 8\n",
    "B2_C = 80\n",
    "B3_C = 80\n",
    "C1_C = 0.4\n",
    "C2_C = 1.6\n",
    "M1_C = 5\n",
    "CL1_C = 4.0\n",
    "\n",
    "#FILTERING PARAMETERS FOR ROBOT DETECTION\n",
    "B1_T = 15\n",
    "B2_T = 100\n",
    "B3_T = 80\n",
    "C1_T = 0.4\n",
    "C2_T = 1.6\n",
    "M1_T = 5\n",
    "CL1_C = 4.0\n",
    "\n",
    "\n",
    "#PARAMETERS TO DETECT THE ENV\n",
    "Min_area_env = 1000   #Min area in pixel of the env\n",
    "Env_approx = 0.02\n",
    "\n",
    "#PARAMETERS TO DETECT THE OBSTACLES\n",
    "Min_area_obs = 1000   #Min area in pixel of the env\n",
    "Square_approx = 0.05\n",
    "\n",
    "#PARAMETERS TO DETECT GOAL\n",
    "Min_area_goal = 50\n",
    "Max_area_goal = 10000\n",
    "\n",
    "#PARAMETERS TO DETECT THE ROBOT\n",
    "Min_area_rob = 100   #Min area in pixel of the env\n",
    "Rob_approx = 0.05\n",
    "\n",
    "#ROBOT CARACTERISTICS\n",
    "R_ROBOT = 20\n",
    "\n",
    "\n",
    "#SYMBOLS FOR THE MAP\n",
    "FREE_SPACE = 0\n",
    "OCCUPIED_SPACE = -1\n",
    "GOAL = -3\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e8a7bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG : \n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "#GLOBAL FRAMEWORK TO USE VISION\n",
    "#EXECUTE CELL ABOVE WITH DEBUG = TRUE FOR TUNING UNTIL EVERYTHING IS CORRECTLY FILTERED AND FOUND\n",
    "cap = cv2.VideoCapture(0)\n",
    "    \n",
    "if not cap.isOpened():\n",
    "    print(\"Could not access webcam\")\n",
    "\n",
    "\n",
    "#INITIALIZATION\n",
    "#GET A FRAME\n",
    "img = com.get_picture_optimized(cap)\n",
    "#COMPUTE TRANSFORMATION MATRIX\n",
    "matrix = com.matrix_perspective(img)\n",
    "#CORRECT IMAGE\n",
    "transformed_image = com.convert_perspective(img,matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "496cd18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[[102 396]\n",
      " [158 421]\n",
      " [140 388]]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "ROBOT FOUND\n",
      "MAP ANALYZED : \n",
      "GOAL FOUND\n",
      "[]\n",
      "[[102 396]\n",
      " [158 421]\n",
      " [140 388]]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "ROBOT FOUND\n"
     ]
    }
   ],
   "source": [
    "#PLOTTING\n",
    "if DEBUG: \n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Perspective Corrected Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#GET GLOBAL MAP\n",
    "global_map = com.get_map(transformed_image)\n",
    "\n",
    "#GET ROBOT POSITION AND ORIENTATION\n",
    "robot = com.get_robot(transformed_image)\n",
    "\n",
    "\n",
    "length = 100\n",
    "end_x = int(robot[0][0] + length * np.cos(robot[1]))\n",
    "end_y = int(robot[0][1] + length * np.sin(robot[1]))\n",
    "end_point = (end_x, end_y)\n",
    "if DEBUG : \n",
    "    global_map4plot = global_map.copy()\n",
    "    cv2.arrowedLine(global_map4plot, robot[0], end_point, color=(2, 2, 2), thickness=10)\n",
    "    plt.imshow(global_map4plot)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cad93f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162014\n"
     ]
    }
   ],
   "source": [
    "solved = global_map[:]\n",
    "path = gb.a_star(global_map, robot[1], 1/10, robot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d6e9e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4. -3.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "## HERE : make infinite loop that launches Filtering, motion and local avoidance\n",
    "empty = np.zeros((SIZE[0], SIZE[1]))\n",
    "for i in path : \n",
    "    empty[i[0]][i[1]] = -4 # marker for path in my debug functions\n",
    "print(np.unique(global_map))\n",
    "#gb.debug_maze_to_bitmap(empty, 20, filename=\"Global_Nav/tests/maze.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e25acb1-c823-4590-bfb3-5b45e361c651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
