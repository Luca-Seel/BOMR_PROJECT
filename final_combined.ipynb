{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1d6cbe-34fb-4d14-8bd2-3ec508687171",
   "metadata": {},
   "source": [
    "# **Basics of Mobile robotics**\n",
    "### **Project**\n",
    "\n",
    "**Paul Huot-Marchand** \n",
    "**Luca Seelbach**\n",
    "**Manuela Waible** \n",
    " \n",
    "\n",
    "**Date:** *2025*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452e01e-bf14-476a-8c23-de648cc0d372",
   "metadata": {},
   "source": [
    "# **INTRODUCTION**\n",
    "Our project take place on a rectangular white environment with black obstacles of any shapes a black circle as goal and a  black isocele triangle on the robot. The goal was to implement global navigation using the camera provided creating a global occupancy map, then applying an A* algorithm to find an optimized path. A filter was implemented to track position of the robot. Local avoidance was implemented to avoid la minuit added obstacles using thymio infrared sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695b99c1-9b64-40b0-a859-30c1c6860de8",
   "metadata": {},
   "source": [
    "## **I Computer Vision**\n",
    "The steps of our computer vision part is as follow : \n",
    "- Detect the environment,\n",
    "- Correct percpective,\n",
    "- detect obstacles and goal to fill occupancy map\n",
    "- detect the robot\n",
    "\n",
    "To do so a general filtering framework was adopted. First convert to gray scale, apply bilateral filter to enhance edge and remove noise, apply canny filter to detect edges, apply morphological filter to close as much as possib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4c4f2938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tdmclient in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (0.1.21)\n",
      "Requirement already satisfied: numpy in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (1.16.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: tqdm in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: websockets in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (from tdmclient) (15.0.1)\n",
      "Requirement already satisfied: zeroconf in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (from tdmclient) (0.147.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: ifaddr>=0.1.7 in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (from zeroconf->tdmclient) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tdmclient numpy scipy opencv-python tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ec37acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import cv2\n",
    "import tqdm\n",
    "from Computer_vision import cv as com\n",
    "#import Filtering as flt \n",
    "from Global_Nav import global_nav as gb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math as m\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from Filtering import Control_fromEKF as control\n",
    "from Filtering import Filtering as filt\n",
    "from Local_Nav import local_nav as ln\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "95ae813b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node 7e5a04de-7cbe-4397-8545-f33016b69c2f"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate the communication between the Thymio and the computer\n",
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "\n",
    "node = await client.wait_for_node()\n",
    "await node.lock() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fffa2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to stop it\n",
    "aw(node.set_variables({\"motor.left.target\":[0], \"motor.right.target\":[0]}))\n",
    "aw(node.unlock())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2b801d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_real_to_pixel(length_cm, env_size_cm, map_size):\n",
    "    \n",
    "    L, W = env_size_cm\n",
    "    height, width = map_size\n",
    "    \n",
    "    # scale factors\n",
    "    scale_x = width / L\n",
    "    scale_y = height / W\n",
    "    \n",
    "    # average scale for uniform scaling\n",
    "    scale = (scale_x + scale_y) / 2\n",
    "    \n",
    "    return length_cm * scale\n",
    "\n",
    "#================HYPERPARAMETESRS======================\n",
    "\n",
    "#SiZE OF THE ENVIRONEMENT (cm)\n",
    "L = 113.5\n",
    "W = 81.3\n",
    "Ratio = L/W\n",
    "\n",
    "#SiZE IN PIXEL OF THE CORRECTED MAP\n",
    "Y_res = 480\n",
    "SIZE = [Y_res, int(Y_res*Ratio)]\n",
    "\n",
    "#SIZE OF THE TRIANGLE (cm)\n",
    "L_T = 10\n",
    "H_T = 3.5\n",
    "L_T_p = length_real_to_pixel(L_T,[L,W], SIZE)\n",
    "H_T_p = length_real_to_pixel(H_T,[L,W], SIZE)\n",
    "\n",
    "#SIZE OF THE GOAL (cm)\n",
    "R_G = 8.4/2\n",
    "\n",
    "R_G_p = length_real_to_pixel(R_G,[L,W], SIZE)\n",
    "\n",
    "# AREA RATIO\n",
    "RATIO_T = (L_T*H_T/2) / (L*W) \n",
    "\n",
    "#FILTERING PARAMETERS FOR THE ORIGINAL IMAGE\n",
    "B1_O = 5\n",
    "B2_O = 50\n",
    "B3_O = 50\n",
    "C1_O = 0.5\n",
    "C2_O = 1.5\n",
    "M1_O = 8\n",
    "CL1_O = 2.0\n",
    "M_O = 5\n",
    "D_O = 5\n",
    "\n",
    "#FILTERING PARAMETERS FOR THE CORRECTED IMAGE\n",
    "B1_C = 10\n",
    "B2_C = 80\n",
    "B3_C = 80\n",
    "C1_C = 0.4\n",
    "C2_C = 1.6\n",
    "M1_C = 5\n",
    "CL1_C = 4.0\n",
    "M_C = 5\n",
    "D_C = 5\n",
    "\n",
    "#FILTERING PARAMETERS FOR ROBOT DETECTION\n",
    "B1_T = 10\n",
    "B2_T = 80\n",
    "B3_T = 80\n",
    "C1_T = 0.4\n",
    "C2_T = 1.6\n",
    "M1_T = 5\n",
    "CL1_T = 2\n",
    "M_T = 2\n",
    "D_T = 2\n",
    "\n",
    "\n",
    "#PARAMETERS TO DETECT THE ENV\n",
    "#Min_area_env = 1920*1080*0.01   #Min area in pixel of the env\n",
    "Min_area_env = 1000\n",
    "Env_approx = 0.1\n",
    "\n",
    "#PARAMETERS TO DETECT THE OBSTACLES\n",
    "Min_area_obs = SIZE[0]*SIZE[1]*0.005   #Min area in pixel of the env\n",
    "Max_area_obs = SIZE[0]*SIZE[1]*0.5   #Max area in pixel of the env\n",
    "Obs_approx = 0.01\n",
    "\n",
    "#PARAMETERS TO DETECT GOAL\n",
    "Min_area_goal = np.pi * R_G_p * R_G_p *0.8\n",
    "Max_area_goal = np.pi * R_G_p * R_G_p * 1.8\n",
    "\n",
    "#PARAMETERS TO DETECT THE ROBOT\n",
    "Min_area_rob = (L_T_p*H_T_p /2) * 0.2   #Min area in pixel of the env\n",
    "Max_area_rob =  (L_T_p*H_T_p /2) * 1.8\n",
    "Rob_approx = 0.08\n",
    "\n",
    "#ROBOT CARACTERISTICS\n",
    "R_ROBOT = 6\n",
    "R_ROBOT_p = length_real_to_pixel(R_ROBOT,[L,W], SIZE)\n",
    "\n",
    "\n",
    "#SYMBOLS FOR THE MAP\n",
    "FREE_SPACE = 0\n",
    "OCCUPIED_SPACE = -1\n",
    "GOAL = -3\n",
    "\n",
    "DEBUG = False\n",
    "#========================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87e035f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8a7bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to camera\n",
    "\n",
    "if DEBUG : \n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "#GLOBAL FRAMEWORK TO USE VISION\n",
    "#EXECUTE CELL ABOVE WITH DEBUG = TRUE FOR TUNING UNTIL EVERYTHING IS CORRECTLY FILTERED AND FOUND\n",
    "cap = cv2.VideoCapture(1)\n",
    "    \n",
    "if not cap.isOpened():\n",
    "    print(\"Could not access webcam\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "496cd18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBOT FOUND\n",
      "MAP ANALYZED : \n",
      "GOAL FOUND\n",
      "ROBOT FOUND\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGUCAYAAAAf7dkWAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAALjVJREFUeJzt3Xt0XPV97/3P3nPTxdIgWbbGwrIRwSUQ2ZTI1LFDYye+UD84lMU5hQaakhM/68EYXPQYDomha+F0tRalT4HkceMsqB8gUKqeU3BKTwmxvAIm1A/BCFxskxoIxpbBQr7Iumtu+3f+EB48uln3vWfm/Vprr2Xt/ZP0nZ81M5/5/X57b8sYYwQAAOAhttsFAAAA9EdAAQAAnkNAAQAAnkNAAQAAnkNAAQAAnkNAAQAAnkNAAQAAnkNAAQAAnkNAAQAAnkNAAQAAnuNqQPnxj3+sqqoq5eXlqaamRr/61a/cLAcAAHiEawHln/7pn1RbW6v7779fb7/9tn7/939fq1ev1tGjR90qCQAAeITl1s0CFy1apC9/+cvatm1bat9ll12m66+/XnV1dW6UBAAAPMLvxi+NxWJqbGzU97///bT9q1at0p49ewa0j0ajikajqa8dx9Hp06c1ffp0WZY16fUCAIDxM8aoo6NDFRUVsu3hJ3FcCSgnT55UMplUeXl52v7y8nI1NzcPaF9XV6cf/OAHU1UeAACYRE1NTZo9e/awbVwJKGf1H/0wxgw6IrJp0yZt3Lgx9XVbW5vmzJmjOVv/u+z80KTXCQAAxs/pieronX+joqKi87Z1JaCUlZXJ5/MNGC1paWkZMKoiSaFQSKHQwCBi54dkF+RNWp0AAGDijWR5hitn8QSDQdXU1KihoSFtf0NDg5YsWeJGSQAAwENcm+LZuHGjvv3tb2vhwoVavHixHnvsMR09elTr1q1zqyQAAOARrgWUm266SadOndJf/MVf6Pjx46qurtaLL76ouXPnulUSAADwCFcXya5fv17r1693swQAAOBB3IsHAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4jt/tAgBMLLvTlhzrvO1MyJEJmSmoCABGj4ACuM2R/McDE/bjfKf9IwooyUhcifL4hP1eAJhIBBTkBiMpOTE/ykpaChwOTcwPkyQjWTFmWwHgXAQUZDS7y5bi5x8tsLtt+U5M3CgFAGByEVCQ0XyfBmR3+NwuAwAwwRhXBgAAnkNAAXKR38jJd9yuAgCGREABcpAJGjnFE7RqGAAmAQEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFAAB4DgEFyEHGMm6XAADDIqAAucaS4lVRt6sAgGERUIBcxDMfgMfxMgUAADyHgAIAADyHgAIAADxn1AHl1Vdf1Te/+U1VVFTIsiz97Gc/SztujNHmzZtVUVGh/Px8LVu2TAcPHkxrE41GtWHDBpWVlamwsFDXXXedjh07Nq4HAgAAsseoA0pXV5euuOIKbd26ddDjDz30kB5++GFt3bpVe/fuVSQS0cqVK9XR0ZFqU1tbqx07dqi+vl6vvfaaOjs7tWbNGiWTybE/EgAAkDX8o/2G1atXa/Xq1YMeM8bo0Ucf1f33368bbrhBkvTUU0+pvLxczz77rG677Ta1tbVp+/btevrpp7VixQpJ0jPPPKPKykrt2rVL11xzzTgeDgAAyAYTugbl8OHDam5u1qpVq1L7QqGQli5dqj179kiSGhsbFY/H09pUVFSouro61aa/aDSq9vb2tA0AAGSvCQ0ozc3NkqTy8vK0/eXl5aljzc3NCgaDKikpGbJNf3V1dQqHw6mtsrJyIssGAAAeMyln8ViWlfa1MWbAvv6Ga7Np0ya1tbWltqampgmrFQAAeM+EBpRIJCJJA0ZCWlpaUqMqkUhEsVhMra2tQ7bpLxQKqbi4OG0DMDbxyqg0/OcFAHDdhAaUqqoqRSIRNTQ0pPbFYjHt3r1bS5YskSTV1NQoEAiktTl+/LgOHDiQagNgEgW4USAA7xv1WTydnZ364IMPUl8fPnxY+/btU2lpqebMmaPa2lpt2bJF8+bN07x587RlyxYVFBTo5ptvliSFw2GtXbtWd999t6ZPn67S0lLdc889mj9/fuqsHgAAkNtGHVDefPNNff3rX099vXHjRknSrbfeqieffFL33nuvenp6tH79erW2tmrRokXauXOnioqKUt/zyCOPyO/368Ybb1RPT4+WL1+uJ598Uj6fbwIeEgAAyHSWMSbjxnvb29sVDod10fY/l12Q53Y5cFHgw5DsDoLtaMS/0CtnmuN2GQBykNPdq4/W/qXa2trOu56Ue/EAAADPIaAAAADPIaAAAADPIaAAAADPIaAgo5mQI5PHgk8AyDajPs0Y8JLEhXFZ8YR8p/r+lK2YJbuVP+uhmAJHJphxJ+4ByEG8kiPjmYBRIhLv+8KR7OkJSZLVZcvfHJBkSbwnS5KcwiQBBUBGIKAgu9iSU/jZlE+ho+SMhJSUAkdCkiTLsWR1M7MJAF5HQEF2syT5pfgXon1fO5Lv5GfTQQlLvhMB92oDAAyJgILcYkvJmX1TQDJSsiQpGSl4OCSdXWvrcKtfAHAbAQW5y5JMfl8qiX6pp2+f+Ww6yJHsbltKElYAwA0EFOBclhS/qG86yD7jkxXvCyi+E4HUvwEAk4+AAgzBuSD5+b/DydQUUOBISFbMYioIACYRAQUYgXNPzY1d2iu7y5b/6GdBBQAw4TjfEhgDp9BRojIq+bimCABMBgIKMEbONEexi6OSTUgBgIlGQAHGwRQ4ildFZQIZEFJ8Rk4B9y0CkBkIKMA4OdMcJeZ4fyTFBEzawl8A8DICCjABnGlO39VqWZMCABOCgAJMEKfAUfyiDJnuAQCPI6AAE8iZ5igxNypZhBQAGA8CCjDBnEJHidkxt8sAgIxGQAEmmN3uk/9YyO0yACCjEVCACWS3+xRoCkrM8ADAuHCpe2CC2O0+BT4KSobL3wPAeDGCAkwAu92nwBHCCQBMFEZQgHGw4pb8R4Oye23v393Y4+UBwLkIKMAYWTFLgQ/yZMUz450/fnGv2yUAwIgRUIAxsHotBY6GMiacSMw+AcgsBBRglKyEpcBHIVlRlnABwGQhoACjYEUtBT7MkxVjOAIAJhMfAbPUwgs+1UUF7W6XkVWsXkuBIyHCCQBMAUZQskjATup7FzdqYfhTTQ/2KOr41ZkIaMenX9AzH39RSUMeHSsrIQUOh2TF6EMAmAoElCzyXyMf6E8v/I2sfjequ2zaae3vKNNbbTNdqiyz9U3rEE4AYCrxiptFLJkB4USSbMvI4trrY2JFz07r8FQBgKnEq26WmJXXqTvm/seQx//q0j3y28kprCjzWQn1jZz08DQBgKnGFE+WCFiOZoZ6hjx+YaiLC4mOVFKyO33yHw8wcgIALiGgAP0EmoKy23hqAICbeBUGznKyN5wkZsckn9tVAMDIZd8rMTAWSSlwLCj7THY+JYyfRdIAMgsT7Dni8aZqroMyjGwOJwCQiXhFzgaW0Y+/9PKwTf69dZYc7hY30NlpHcIJAHgKH6mzREkg6nYJmYdwAgCeRUBBziKcAIB38eqM3JPlC2IBIBswgoLc4hBOACATEFCQU5jWAYDMwCs1coLvhF/+5oDkcCYTAGQCAgqynu+EX/5Pgm6X4RqT78iEHLfLAIBRYYoHWc138rORkxzmFCZl8riSLIDMwggKslauj5wAQCZjBCULXFN2VIW++JDHf30mok+ihVNYkft8JwknAJDJCChZYGXZERX6hw4oe9vKdbx32hRW5C7fKb/8x3N7WgcAMh0BBVnHilmcrQMAGY6AAgAAPIeAAgAAPIeAAgAAPIeAAgAAPIfroAAAhmckJQfu9rX75GvpO2MuWZpQcmZiautCViOgANnMNjL5XOYeI5SU7A7fgN12ty3fieFP3bfinDmHiUVAAbKYCRglSwf56IucZiUk3/GBFzK0Epbs9oEBBXADASXD5fsSyreHfgOKOT51JrhoGZDtBh3BSEqBw3kD9xtGPOB9BJQMt3rGR1o148iQx9/tLNX2pi9NYUUAJpN9xier/70fHUv+Y9zaAdllVGfx1NXV6aqrrlJRUZFmzpyp66+/XocOHUprY4zR5s2bVVFRofz8fC1btkwHDx5MaxONRrVhwwaVlZWpsLBQ1113nY4dOzb+R4Mh5NYnpeQFCZkgd+9FZvN/ElDgaHCQLSR//41wgiw0qoCye/du3XHHHXr99dfV0NCgRCKhVatWqaurK9XmoYce0sMPP6ytW7dq7969ikQiWrlypTo6OlJtamtrtWPHDtXX1+u1115TZ2en1qxZo2SSuXKMn8k3ko+AAm+xEpas2MAt8NuQggfzB2y+EwHZrf4Bm7z6p+1Y3q0NGWlUUzwvvfRS2tdPPPGEZs6cqcbGRn3ta1+TMUaPPvqo7r//ft1www2SpKeeekrl5eV69tlnddttt6mtrU3bt2/X008/rRUrVkiSnnnmGVVWVmrXrl265pprJuihAYC77A5bVqzvc6DvpF9Wb/Zeesp32i8nnJRTzAdNTIxxPVva2tokSaWlpZKkw4cPq7m5WatWrUq1CYVCWrp0qfbs2SNJamxsVDweT2tTUVGh6urqVJv+otGo2tvb0zYA8DrfKb/8x4LyHwtmdTgBJsOYnzHGGG3cuFFXX321qqurJUnNzc2SpPLy8rS25eXlqWPNzc0KBoMqKSkZsk1/dXV1CofDqa2ysnKsZQMAgAww5oBy55136p133tE//uM/DjhmWemLMo0xA/b1N1ybTZs2qa2tLbU1NTWNtWwAAJABxhRQNmzYoBdeeEEvv/yyZs+endofiUQkacBISEtLS2pUJRKJKBaLqbW1dcg2/YVCIRUXF6dtAAAge40qoBhjdOedd+r555/XL3/5S1VVVaUdr6qqUiQSUUNDQ2pfLBbT7t27tWTJEklSTU2NAoFAWpvjx4/rwIEDqTYAJkb84qjbJQDAmIzqLJ477rhDzz77rP7lX/5FRUVFqZGScDis/Px8WZal2tpabdmyRfPmzdO8efO0ZcsWFRQU6Oabb061Xbt2re6++25Nnz5dpaWluueeezR//vzUWT0AJojNeZ8AMtOoAsq2bdskScuWLUvb/8QTT+g73/mOJOnee+9VT0+P1q9fr9bWVi1atEg7d+5UUVFRqv0jjzwiv9+vG2+8UT09PVq+fLmefPJJ+XzcA2I0LMvIbw19I7iksVX326umsCIA50pE4gp2+PquEQJgVCxjTMZ9xGpvb1c4HNZF2/9cdsEg95nIEeWhbr286J8VsAcPKQnHVs2/f0vdydy7F0/wvTxZPZzWGftStww3tHBV6EC+lMyNgBKvinIdFAzL6e7VR2v/Um1tbeddT8oreAazZIYMJ7kuWZaQU5JwuwwAwBjx2QpZKVmaUDIsWWUJBY4G++7cmq3D7MOsM8m44VEA+AwBBdnLJ5kCR7Ev9vZ9ecIvu80nu8uba51MniMTGF2kMAWOEpH4JFUEAO4hoCBnJGcklJyekO9U35+9vzkwaaMqiUhs1BOoTnFSJsSYBwBIBBTkGrsvqEh9gcB3xi/fiaGfBk6+o8SFsVH/GpNH0EDu8X8cUGxaktWNmBAEFOQsEzJKlMeVKGeKBJgIZ+/cDEwE/poAAIDnEFAAAIDnEFAAAIDnEFAy2G1z9g97/MmPL1fMePOUWgAAhkNAyWDLSo8Ne/zfW2cp4fBfDLhptNe2AdCHdy8AmETxi6JulwBkJAIKAADwHAIKAADwHAIKAADwHAIKAADwHAIKAGDCWNHJuQEncg8BBQAwYQJNIbdLQJYgoAAAAM8hoGSo2fkdCtrOkMdbogXqSASnsCIAACYOASVD3Va5XzND3UMe/9eWKv1H+4wprAgAgIlDQAEAAJ5DQAEAAJ5DQAGASWT8Rk5x0u0ygIxDQAGAyeSTnGkEFGC0CCgZ5oriE5LF7dsBANnN73YBOL+gndTGqrdkW0arZxzRz0/M1ZXFJ877fTfOek87Pv2C4o5vCqoEAGDiEFAywP9z2a/0B2UfyfrsCtL/bfa75/2eGyK/VdBK6r/NfleOLP3g/UV6o61cMlyGGgDgfUzxZIDZeZ2pcDJSJYFeFfrjuqTwjH6nsFV/P3+XAtbQF3YDAMBLCCget7zsqC4MdY775zBuAgDIJAQUj2tsK9eJWP64f07QTur7F785ARUBwNCsXlu+E6wewPgRUDzuTDykmBn/IteY49Nff7hwAioCgGEYyUoyZovxI6BkgMeOVsuZgMWtnJwMAMgUBJQM8IuTc3XXu0vVmQiM6fvbE0HdcXCZ4ob/bgBAZuAdKwMYY+mlExfp/veWqC0eGtX3norl6d7/vFqvnp7NKcYAgIzBSqYM8mJLlRxj6UeX75Y1gqvJJo2t7x/6ql45VTkF1QEAMHEYQckwe1pn6dNYwXnbnYmHdNuBb2j36dlTUBWAYfmNZLMKDBgNAkqGaU+E9H/t/4be67pg0OPGSPWf/I7uO/RV7T41W4ZpHcB1yZKknEIulAiMBgElA/2mc7ru/s3X1BItkGMsGWPJ+Wz7ydEF+sEHX1HDyTlulwkAwJixBiVD/Wdnqa7Ze70sSbfPfUf1n1yq1nhIPY5fCYfcCQDIbASUDNaZCEqSHvotF2ADAGQXPmoDAADPIaAAAADPIaAAACaU1WnLinMGIcaHgAIAmFB2l09WjICC8SGgAAAAzyGgAAAAzyGgAAAAzyGgAAAAzyGgAMAUSE5PSKwbBUaMgAIAU8AJJyWLOxoDI0VAAQAAnkNAAQAAnkNAAQAAnkNAAQAAnkNAAQBMPNYDY5wIKACACec/GiKkYFwIKACACWcluOgLxoeAAgAAPIeAAgAAPIeAAgAAPIeAAgBThWUZwIgRUABgisSrom6XAGSMUQWUbdu2acGCBSouLlZxcbEWL16sn//856njxhht3rxZFRUVys/P17Jly3Tw4MG0nxGNRrVhwwaVlZWpsLBQ1113nY4dOzYxjwYAPMzwkRAYsVE9XWbPnq0HH3xQb775pt5880194xvf0B/+4R+mQshDDz2khx9+WFu3btXevXsViUS0cuVKdXR0pH5GbW2tduzYofr6er322mvq7OzUmjVrlEwmJ/aRAQCAjGUZY8Z1KZ3S0lL9zd/8jb773e+qoqJCtbW1+t73viepb7SkvLxcf/3Xf63bbrtNbW1tmjFjhp5++mnddNNNkqRPPvlElZWVevHFF3XNNdeM6He2t7crHA7rou1/LrsgbzzlA8CUsXpsBd/LkdcsS4rO72bdDdI43b36aO1fqq2tTcXFxcO2HfOAYzKZVH19vbq6urR48WIdPnxYzc3NWrVqVapNKBTS0qVLtWfPHklSY2Oj4vF4WpuKigpVV1en2gwmGo2qvb09bQMAANlr1AFl//79mjZtmkKhkNatW6cdO3bo8ssvV3NzsySpvLw8rX15eXnqWHNzs4LBoEpKSoZsM5i6ujqFw+HUVllZOdqyAQBABhl1QLn00ku1b98+vf7667r99tt166236t13300dt6z08TxjzIB9/Z2vzaZNm9TW1pbampqaRls2AADIIKMOKMFgUJdccokWLlyouro6XXHFFfrhD3+oSCQiSQNGQlpaWlKjKpFIRLFYTK2trUO2GUwoFEqdOXR2AwB4mJF8p/xuV4EMNu6T3owxikajqqqqUiQSUUNDQ+pYLBbT7t27tWTJEklSTU2NAoFAWpvjx4/rwIEDqTYAgOxgn/G5XQIy2Kji7X333afVq1ersrJSHR0dqq+v1yuvvKKXXnpJlmWptrZWW7Zs0bx58zRv3jxt2bJFBQUFuvnmmyVJ4XBYa9eu1d13363p06ertLRU99xzj+bPn68VK1ZMygMEAACZZ1QB5dNPP9W3v/1tHT9+XOFwWAsWLNBLL72klStXSpLuvfde9fT0aP369WptbdWiRYu0c+dOFRUVpX7GI488Ir/frxtvvFE9PT1avny5nnzySfl8JG0AANBn3NdBcQPXQQGQiXLqOiiSnMKk4pdweX98bkqugwIAGCWfkclz3K4CyAgEFACYIiZolCxJuF0GkBE4BwwAMDJ+IzPMZa0SFTGZgnNGiOyMW0EADyGgAADkFCVlAsMHiuSsmAzvGpgi/KkBQA5IXBiT8Q0dQExRkvABT+HPEQA8zgSNpGFGN2wpfnF02DsHGz/TLcgsBBQAcJMlJUuHXzibqIhxSgNyDgEFAKaQE04qHjrn2iCW5BQn3SsI8CgCCgBMIRMyMiHvBBIraqVmj0we00DwDgIKAOQA32m/NEgu8h8PSMaSLCk6v3vYdSzAVCKgAEAW8X8ckBUduGDF7rQ17EVMAI8hoACAx1m91oBw4f8kILt7kJWzDiEE2YGAAgAe4Ts1yDSMkfwtAYIHcg4BBQAm0yDrTv2fBGT1DjIN0227F0SM5P84qMTsmDu/H+iHgAIA42TFLFnxgcHC92mgb+1Hfx5dC2L3erMu5CYCCgCMgu+Uf0AYsdt9snq4khowkQgoAHLbEFeR9zcHZHf5Buy3ei3WgwBTgIACICdYUUtWbJBpmBMB2R0DgwgAdxFQAGQd3yl/3xVSz2F3+WQNdlouAE8ioADwPiPJGbjb/+ngox9WjGkYINMRUAB4hhW1Bj391nfaL7udaRgglxBQAEw5u8uWfWZg4LC7mYZxkxW1ZXfYcooGGa4CphgBBcDEcCRrkPc1X0tgwOiHlbSkBFMwnpOwZHf7CCjwBAIKgFGxotag1/zwnfHLbmMaBsDEIKAAGJTVbffdG6Yfu9dmGgbApCOgAEixO2z5m0KSPpuuSTINA8AdBBQAnzOD31MGAKYa47QAAMBzCCgAAMBzCCgAgBSr25aVcLsKgIACADiH3e6TYrw1wH38FQL4nG0kn3G7CgAgoAD4nDPNUbKE8X0A7iOgAAAAzyGgAAAAzyGgAAAAzyGgAAAAzyGgAADS2IPcrRqYavwVAgDS+D8JuF0CQEABAADeQ0ABAMADQh92SYYLJZ7ld7sAAAByi1HJ/2iWHXPS9ha+cUZdC8OSbaXtP/PNmUqGc2/ajYACALmo/y0NLCl2cVSyjGQN/i0YOyuaVKAlpplbj0hGCnzSK8sZ2C780skB+wreapMJ2DqzZqa6a4rlFOTGW3duPEoAI2byTd89eRzepbKFyXdkgp+/G5qAUeLCuIsV5Q4r7qjg7XYV7zypvN90yhrDDE6gOSZJmrHtqJwin06urVT0CwVKTA9OcLXeQkABkCZZmpCvxS8rSkDJRMnyuEwg/V3QmZaUCbG2YapN29Oq/P9oV9GvWifk51mSfB1JlT/6kXqqp6n3dwrV+l9nTcjP9iICCgBkAOMfOCUTv7h3wKkOJsAUjeuM0bTXz6hse5PsnkHmcSZA/oHOvhGZmFHrH0VkAtl3zgsBBQA8xhQ4MqFzpmT8RokKpmQyQehwt0Ifdmv69mOTnhOtpHTB/2qRlTTqmT9N3b8bnuTfOLUIKADgomR5PC2MSJJT4DAlk4GCTT2ase2ogsd6p/T3hn9+QtNePa2Ta2er6yslU/q7JxMBBQAmg21k0l5hjeIXRwdOyfiZkskKxij4Uc+Uh5OzfF1J5R/oVHdNOGumewgoADBOpjApJ88M2JcsSbpUEaZa4a/PaMZPjrpaQ/EvT8nJt3X6WxUDrqWSiQgoADAKiUhswPSLKXBkgkzJ5KrC11tV9v8dG9MpxBMt/OIJyW/p9E0VbpcybgQUAJAkn0k/U8aS4lVRGbvfuw6vmjiHFXOU/26nfJ3eGC2zjJS/r0O+/yOhZFFm/7FmdvUAMAZOYVImv9/C1EJHzgXeeJNB5gh92K3iXafcLiNN6EiPineeVOt/ibhdyrgQUABktcSsmEz/9SF5TMlgAiSNSv652e0qBlW4p1Wdiy9QvCLP7VLGjIACIDP5zICQEa+KyvS/x0x2nNAADwo0R5X3XpfbZQwqeDyq0G+7Fa8IKVNPEyOgABjAKUnK1+ydd3ZnWlKmoN+UTD5TMnBX2RPHZCW8OxJXtr1JXUsukPERUABkieT0uHzN7t/ePTE7JhPqu2hZ//vLAK4ypm/zuqQkn9tFjI13PiIBQD9OgSNnmkM4geeE/+2E8v7Tm9M7Z9kxo/IffuR2GWNGQAEAYJSspPHEdU/Ox4pPzs0KpwIBBYBnBY4F3S4BgEsIKAA8y+rNzMV9AMaPgAIAADyHgAIAwCgEjveq6GVvXT12KMHDPZr2/7e6XcaYjCug1NXVybIs1dbWpvYZY7R582ZVVFQoPz9fy5Yt08GDB9O+LxqNasOGDSorK1NhYaGuu+46HTt2bDylAAAwJeKzQupYVup2GSMSq8pX51cucLuMMRlzQNm7d68ee+wxLViwIG3/Qw89pIcfflhbt27V3r17FYlEtHLlSnV0dKTa1NbWaseOHaqvr9drr72mzs5OrVmzRskkF10CAHidJVkZtD4qk2o9x5gCSmdnp2655RY9/vjjKikpSe03xujRRx/V/fffrxtuuEHV1dV66qmn1N3drWeffVaS1NbWpu3bt+tv//ZvtWLFCl155ZV65plntH//fu3atWtiHhUAAMhoYwood9xxh6699lqtWLEibf/hw4fV3NysVatWpfaFQiEtXbpUe/bskSQ1NjYqHo+ntamoqFB1dXWqTX/RaFTt7e1pG4AcYCS7i6VyQC4a9TO/vr5eb731lurq6gYca27uu6tjeXl52v7y8vLUsebmZgWDwbSRl/5t+qurq1M4HE5tlZWVoy0bwCgYn5QsTbhdhmQs+Vrcv+Q+gKk3qoDS1NSku+66S88884zy8oa+hbPVb77LGDNgX3/Dtdm0aZPa2tpSW1NT02jKBjBaluQUsSYMGEr7yunqvaTA7TKG5QQsnbhtjttljNmoAkpjY6NaWlpUU1Mjv98vv9+v3bt360c/+pH8fn9q5KT/SEhLS0vqWCQSUSwWU2tr65Bt+guFQiouLk7bAABwi1Pglwl6fPrRkpIXZO49gUfVu8uXL9f+/fu1b9++1LZw4ULdcsst2rdvny6++GJFIhE1NDSkvicWi2n37t1asmSJJKmmpkaBQCCtzfHjx3XgwIFUGwAAvK5tzUwZD98puO2b5TJ2Zp7BI0mjilZFRUWqrq5O21dYWKjp06en9tfW1mrLli2aN2+e5s2bpy1btqigoEA333yzJCkcDmvt2rW6++67NX36dJWWluqee+7R/PnzByy6BQDAq3rmT1OiNKjAiZjbpQyQLPSp+8vFGXuKsTTKgDIS9957r3p6erR+/Xq1trZq0aJF2rlzp4qKilJtHnnkEfn9ft14443q6enR8uXL9eSTT8rn83AUBQDgHMZn68Ttc1TxFx+4XcoA7X8wQ9Eqb6+ROR/LGJMBN4xO197ernA4rIu2/7nsgqEX6wIYHavblr+l73OLFbdldbs/x+4UJxWvirpdBjAoX0dCZdubVPhGm9ulpMRmhfTpxirFL/Te+6PT3auP1v6l2trazrueNHNXzwA4PyNZsYFDvFaPrcCx4KDt5XhrSNju8Ml3yq/kdA+c9gz0kyzyq+eyacrf1y475v7nfaO+y9t7MZyMFgEFyAZG8p0a+HS2EpZ8n2b4dUTMZxvgUe3XzJAdc1RSf1yWy3+rXYvCOnF75p5afC4CCpBJjBQ4Ehr4hm36RhoAuOPMtTOlhFHp/xz8gqNToeuqsE59t1LG5/7U7EQgoAAeF/gomB4+PDYFA0CSban3S0VK/uKkfO1TPx3pBC31XjZNyaLseVvPnkcCZCvHIpQAGaD3dwp14rZK5e/vUPFLJzVVz9quq8LquWya2v9gxhT9xqlBQAEAYIJ0XxlW94JiJYv8Kvnn5kldk2Ikdf9eWCfXVmbVyMlZ2feIAABwk8/SmT8sl3yWCve2KfTb7gn/FfFZIUXn5uvEHXOyZs1JfwQUAJ5nt/uUvCDBKxYyh23pzHXlal9VpvCLJ1Sw94xCR3rH/WOdfFtt185U11VhxSrzJ6BQ7+LpDsDz7A6frKQl4+d8Y2QWJ8+n1hsi6vxqiYJHejTjx0ckSVbMjHiNihOwJEtqu3amuheGM/4KsSNFQAEAYJLFy0OKlwfVXTNfMtLM//eI7J5kWpvgRz2Kzc1X/+Ry4v+sVHJ6oO/Gfxl8b53RIqAAADAlLBlfX8D49P+uGnC08Net6rrqAimD70A8kQgoAAB4QNeiErdL8JTsXPoLAAAyGgEFAAB4DgEFQEYIHAm5XQKAKURAAZARrBgLB4FcQkABAACeQ0ABAACeQ0ABAACeQ0ABAACeQ0ABvCwpyXG7CACYegQUwMN8p/2yu3xul+ENRrI7eMkCcgXPdgCZwbHkO83dOYBcQUABAACeQ0ABAACeQ0ABAACeQ0ABAACeQ0ABAACeQ0ABkDmM2wUAmCoEFAAZw27zy3ea68IAuYCAAiDDWG4XAGAKEFAAAIDncFlGAJ7mFCXTvjYBbk4E5AICCgDXJCJxyR5m5aslJcsSU1cQAM8goAAYG9/wp9QYW4pf3Dt8mzxOywEwOAIKgIEsySlODtskPifKKjYAk4aAAuSgREVs+JNhbKNk6fABBQAmEwEFyDT+80yt+I3iF0WHbmBJJsjUCgBvI6AAHmbyHDkXfL5I1FhSYk7MxYoAYGoQUAAPc4ocOUUEEgC5hyVuAADAcwgoAADAcwgoAADAcwgoAADAcwgoAADAcwgoAADAcwgoAADAcwgoAADAcwgoAADAcwgoAADAcwgoAADAczLyXjzG9N2J1ekZ5o6tAADAU86+b599Hx+OZUbSymOOHTumyspKt8sAAABj0NTUpNmzZw/bJiMDiuM4OnTokC6//HI1NTWpuLjY7ZI8q729XZWVlfTTedBPI0M/jQz9NDL008hkUz8ZY9TR0aGKigrZ9vCrTDJyise2bV144YWSpOLi4oz/D5sK9NPI0E8jQz+NDP00MvTTyGRLP4XD4RG1Y5EsAADwHAIKAADwnIwNKKFQSA888IBCoZDbpXga/TQy9NPI0E8jQz+NDP00MrnaTxm5SBYAAGS3jB1BAQAA2YuAAgAAPIeAAgAAPIeAAgAAPCcjA8qPf/xjVVVVKS8vTzU1NfrVr37ldklT6tVXX9U3v/lNVVRUyLIs/exnP0s7bozR5s2bVVFRofz8fC1btkwHDx5MaxONRrVhwwaVlZWpsLBQ1113nY4dOzaFj2Jy1dXV6aqrrlJRUZFmzpyp66+/XocOHUprQz/12bZtmxYsWJC6CNTixYv185//PHWcfhqorq5OlmWptrY2tY9+6rN582ZZlpW2RSKR1HH66XMff/yx/uRP/kTTp09XQUGBfvd3f1eNjY2p4znfVybD1NfXm0AgYB5//HHz7rvvmrvuussUFhaaI0eOuF3alHnxxRfN/fffb5577jkjyezYsSPt+IMPPmiKiorMc889Z/bv329uuukmM2vWLNPe3p5qs27dOnPhhReahoYG89Zbb5mvf/3r5oorrjCJRGKKH83kuOaaa8wTTzxhDhw4YPbt22euvfZaM2fOHNPZ2ZlqQz/1eeGFF8y//du/mUOHDplDhw6Z++67zwQCAXPgwAFjDP3U3xtvvGEuuugis2DBAnPXXXel9tNPfR544AHzpS99yRw/fjy1tbS0pI7TT31Onz5t5s6da77zne+YX//61+bw4cNm165d5oMPPki1yfW+yriA8nu/93tm3bp1afu++MUvmu9///suVeSu/gHFcRwTiUTMgw8+mNrX29trwuGw+clPfmKMMebMmTMmEAiY+vr6VJuPP/7Y2LZtXnrppSmrfSq1tLQYSWb37t3GGPrpfEpKSszf//3f00/9dHR0mHnz5pmGhgazdOnSVEChnz73wAMPmCuuuGLQY/TT5773ve+Zq6++esjj9JUxGTXFE4vF1NjYqFWrVqXtX7Vqlfbs2eNSVd5y+PBhNTc3p/VRKBTS0qVLU33U2NioeDye1qaiokLV1dVZ249tbW2SpNLSUkn001CSyaTq6+vV1dWlxYsX00/93HHHHbr22mu1YsWKtP30U7r3339fFRUVqqqq0h//8R/rww8/lEQ/neuFF17QwoUL9Ud/9EeaOXOmrrzySj3++OOp4/RVhq1BOXnypJLJpMrLy9P2l5eXq7m52aWqvOVsPwzXR83NzQoGgyopKRmyTTYxxmjjxo26+uqrVV1dLYl+6m///v2aNm2aQqGQ1q1bpx07dujyyy+nn85RX1+vt956S3V1dQOO0U+fW7RokX7605/qF7/4hR5//HE1NzdryZIlOnXqFP10jg8//FDbtm3TvHnz9Itf/ELr1q3Tn/3Zn+mnP/2pJP6mpAy9m7FlWWlfG2MG7Mt1Y+mjbO3HO++8U++8845ee+21Acfopz6XXnqp9u3bpzNnzui5557Trbfeqt27d6eO53o/NTU16a677tLOnTuVl5c3ZLtc7ydJWr16derf8+fP1+LFi/WFL3xBTz31lL7yla9Iop8kyXEcLVy4UFu2bJEkXXnllTp48KC2bdumP/3TP021y+W+yqgRlLKyMvl8vgHJsKWlZUDKzFVnV8sP10eRSESxWEytra1DtskWGzZs0AsvvKCXX35Zs2fPTu2nn9IFg0FdcsklWrhwoerq6nTFFVfohz/8If30mcbGRrW0tKimpkZ+v19+v1+7d+/Wj370I/n9/tTjzPV+GkxhYaHmz5+v999/n7+nc8yaNUuXX3552r7LLrtMR48elcRrlJRhASUYDKqmpkYNDQ1p+xsaGrRkyRKXqvKWqqoqRSKRtD6KxWLavXt3qo9qamoUCATS2hw/flwHDhzImn40xujOO+/U888/r1/+8peqqqpKO04/Dc8Yo2g0Sj99Zvny5dq/f7/27duX2hYuXKhbbrlF+/bt08UXX0w/DSEajeo3v/mNZs2axd/TOb761a8OuPTBe++9p7lz50riNUpS5p5mvH37dvPuu++a2tpaU1hYaD766CO3S5syHR0d5u233zZvv/22kWQefvhh8/bbb6dOtX7wwQdNOBw2zz//vNm/f7/51re+NeipabNnzza7du0yb731lvnGN76RNaemGWPM7bffbsLhsHnllVfSTnfs7u5OtaGf+mzatMm8+uqr5vDhw+add94x9913n7Ft2+zcudMYQz8N5dyzeIyhn866++67zSuvvGI+/PBD8/rrr5s1a9aYoqKi1Gs0/dTnjTfeMH6/3/zVX/2Vef/9980//MM/mIKCAvPMM8+k2uR6X2VcQDHGmL/7u78zc+fONcFg0Hz5y19OnTqaK15++WUjacB26623GmP6Tk974IEHTCQSMaFQyHzta18z+/fvT/sZPT095s477zSlpaUmPz/frFmzxhw9etSFRzM5BusfSeaJJ55ItaGf+nz3u99NPZ9mzJhhli9fngonxtBPQ+kfUOinPmev1REIBExFRYW54YYbzMGDB1PH6afP/eu//quprq42oVDIfPGLXzSPPfZY2vFc7yvLGGPcGbsBAAAYXEatQQEAALmBgAIAADyHgAIAADyHgAIAADyHgAIAADyHgAIAADyHgAIAADyHgAIAADyHgAIAADyHgAIAADyHgAIAADyHgAIAADznfwP0Z6YHRyN6igAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#INITIALIZATION\n",
    "#GET A FRAME\n",
    "img = com.get_picture_optimized(cap)\n",
    "#img = cv2.imread(\"02.png\")\n",
    "#COMPUTE TRANSFORMATION MATRIX\n",
    "matrix = com.matrix_perspective(img)\n",
    "#CORRECT IMAGE\n",
    "transformed_image = com.convert_perspective(img,matrix)\n",
    "\n",
    "#PLOTTING\n",
    "if DEBUG: \n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Perspective Corrected Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#GET GLOBAL MAP\n",
    "global_map = com.get_map(transformed_image)\n",
    "\n",
    "#GET ROBOT POSITION AND ORIENTATION\n",
    "robot = com.get_robot(transformed_image)\n",
    "\n",
    "\n",
    "length = 100\n",
    "end_x = int(robot[0][0] + length * np.cos(robot[1]))\n",
    "end_y = int(robot[0][1] + length * np.sin(robot[1]))\n",
    "end_point = (end_x, end_y)\n",
    "global_map4plot = global_map.copy()\n",
    "cv2.arrowedLine(global_map4plot, [int(robot[0][0]), int(robot[0][1])], end_point, color=(2, 2, 2), thickness=10)\n",
    "plt.imshow(global_map4plot)\n",
    "plt.show()\n",
    "if DEBUG : \n",
    "    global_map4plot = global_map.copy()\n",
    "    cv2.arrowedLine(global_map4plot, robot[0], end_point, color=(2, 2, 2), thickness=10)\n",
    "    plt.imshow(global_map4plot)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda900a5-037e-4ee5-9b5f-32913256fcef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4cad93f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "670\n",
      "158\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "global_map = global_map.astype(int)\n",
    "solved = global_map[:]\n",
    "path = path = gb.a_star(global_map, robot[1], 0.25, \n",
    "                 (int(round(robot[0][1])), int(round(robot[0][0]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4d0455a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help functions \n",
    "# Utility to pop waypoint if we pass it by local obstacle avoidance\n",
    "thresh = 120\n",
    "def dist_mm(p, q):\n",
    "    return float(np.hypot(p[0] - q[0], p[1] - q[1]))\n",
    "\n",
    "# Utilities to add global obstacles to repulsion vector in local obstacle avoidance\n",
    "EPSILON = 1e-2\n",
    "def add_unknown_repulsion(curr_pos, unknown_cells, UNKNOWN_WEIGHT=0.5, p=1.0, max_range=15.0):\n",
    "    \"\"\"\n",
    "    curr_pos: (x_cm, y_cm)\n",
    "    unknown_cells: iterable of (x_cm, y_cm) of the centers of -1 cells\n",
    "    UNKNOWN_WEIGHT: small global weight\n",
    "    p: distance power for attenuation\n",
    "    max_range: ignore far unknowns (cm) to limit computation/noise\n",
    "    \"\"\"\n",
    "    rx, ry = curr_pos\n",
    "    ux, uy = 0.0, 0.0\n",
    "    for cx, cy in unknown_cells:\n",
    "        dx = rx - cx\n",
    "        dy = ry - cy\n",
    "        d = m.hypot(dx, dy)\n",
    "        if d < 1e-6 or d > max_range:\n",
    "            continue\n",
    "        # unit vector from cell to robot\n",
    "        ux += (dx / d) * (1.0 / ((d + EPSILON)**p))\n",
    "        uy += (dy / d) * (1.0 / ((d + EPSILON)**p))\n",
    "    return (UNKNOWN_WEIGHT * ux, UNKNOWN_WEIGHT * uy)\n",
    "\n",
    "def unknown_cells_world(grid, cell_size_cm_x, cell_size_cm_y):\n",
    "    \"\"\"\n",
    "    Turn indices of -1 cells into world coordinates (cm).\n",
    "    origin_world_cm: (x0_cm, y0_cm) of grid cell (0,0)\n",
    "    res_cm: cell size (cm)\n",
    "    \"\"\"\n",
    "    x0, y0 = (0, 0)\n",
    "    cells = []\n",
    "    H, W = len(grid), len(grid[0])\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            if grid[i][j] == -1:\n",
    "                cx = x0 + (j + 0.5) * cell_size_cm_x\n",
    "                cy = y0 + (i + 0.5) * cell_size_cm_y\n",
    "                cells.append((cx, cy))\n",
    "    return cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c589ca-efaf-4c45-b496-9c4d14dc603a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBOT FOUND\n",
      "MAP ANALYZED : \n",
      "GOAL FOUND\n",
      "ROBOT FOUND\n",
      "480\n",
      "670\n",
      "156\n",
      "102\n",
      "318794\n",
      "ROBOT FOUND\n",
      "Connected: Node 7e5a04de-7cbe-4397-8545-f33016b69c2f\n",
      "ROBOT FOUND\n",
      "get_motor_meas 1 0\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 143.95577233869847 263.9279091131798 1.6594522086623338\n",
      "ROBOT FOUND\n",
      "get_motor_meas -13 15\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 143.95577233869847 263.9279091131798 1.6594522086623338\n",
      "ROBOT FOUND\n",
      "get_motor_meas -65 58\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 144.91687692635884 264.39779756037456 1.5263811115479855\n",
      "ROBOT FOUND\n",
      "get_motor_meas -134 139\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 153.2496921049685 348.30556477207153 1.991459675927931\n",
      "ROBOT FOUND\n",
      "get_motor_meas -141 140\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 149.96962773486973 261.16497712146423 1.312544106983858\n",
      "ROBOT FOUND\n",
      "get_motor_meas -143 144\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 149.49176531137417 265.363900862069 1.165904540509813\n",
      "ROBOT FOUND\n",
      "get_motor_meas -126 127\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 152.77468925919953 263.625146782527 1.0489620469804861\n",
      "ROBOT FOUND\n",
      "get_motor_meas -131 124\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 153.99434030949715 263.85164231477216 0.9530406012286641\n",
      "ROBOT FOUND\n",
      "get_motor_meas -126 110\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 155.3482035987541 262.3241277137793 0.8598869536113304\n",
      "ROBOT FOUND\n",
      "get_motor_meas -92 89\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 157.08125657167045 259.44825308783163 0.7248661436153409\n",
      "ROBOT FOUND\n",
      "get_motor_meas -86 88\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 157.6185607032187 259.62677949372966 0.647811426927098\n",
      "ROBOT FOUND\n",
      "get_motor_meas -77 80\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 158.1961232977702 258.11218837371854 0.5700404636997107\n",
      "ROBOT FOUND\n",
      "get_motor_meas -59 65\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 156.65949267968583 257.48877583465816 0.5434775947130438\n",
      "ROBOT FOUND\n",
      "get_motor_meas -63 63\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 156.35611081970342 257.45865814696486 0.4236689218775169\n",
      "ROBOT FOUND\n",
      "get_motor_meas -60 57\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 158.80404538394 254.6917166289593 0.41606450572382214\n",
      "ROBOT FOUND\n",
      "get_motor_meas -43 45\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 156.86101061203098 256.01986200202566 0.3566201359514314\n",
      "ROBOT FOUND\n",
      "get_motor_meas -42 41\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 158.0792208048266 253.37112780713343 0.3332443011116721\n",
      "ROBOT FOUND\n",
      "get_motor_meas 29 82\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 157.52496139989705 255.14883620689656 0.26299473168091925\n",
      "ROBOT FOUND\n",
      "get_motor_meas 298 253\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 161.6417910447761 254.0625 0.3217505543966422\n",
      "ROBOT FOUND\n",
      "get_motor_meas 214 258\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 175.82089552238804 254.0625 0.24497866312686414\n",
      "ROBOT FOUND\n",
      "get_motor_meas 208 263\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 183.48151189044953 254.44850196463653 0.2234766011406337\n",
      "ROBOT FOUND\n",
      "get_motor_meas 222 257\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 191.54551560055154 255.7457096696984 0.17593962545252811\n",
      "ROBOT FOUND\n",
      "get_motor_meas 214 266\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 199.4062903475701 256.96121539792387 0.16820677185708566\n",
      "ROBOT FOUND\n",
      "get_motor_meas 249 255\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 207.34393518827315 256.2138943795118 0.1864869016672169\n",
      "ROBOT FOUND\n",
      "get_motor_meas 269 262\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 217.10778323149353 257.7932969798658 0.14707835538840217\n",
      "ROBOT FOUND\n",
      "get_motor_meas 229 259\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 225.6149384083947 255.10537663755457 0.13255153229667432\n",
      "ROBOT FOUND\n",
      "get_motor_meas 237 247\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 232.73524992487228 255.85401006711407 0.14707835538840291\n",
      "ROBOT FOUND\n",
      "get_motor_meas 261 263\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 244.81434291954858 254.18643292682924 0.11065722117389619\n",
      "ROBOT FOUND\n",
      "get_motor_meas 243 253\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 249.14288590772944 254.6891589376054 0.1289107716839915\n",
      "ROBOT FOUND\n",
      "get_motor_meas 240 258\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 258.09428467419 255.3844512195122 0.11065722117389565\n",
      "ROBOT FOUND\n",
      "get_motor_meas 258 268\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 269.40680865336236 254.85570786516854 0.08490179344972282\n",
      "ROBOT FOUND\n",
      "get_motor_meas 246 260\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 276.48041443554996 256.8022422722789 0.07259945373049481\n",
      "ROBOT FOUND\n",
      "get_motor_meas 225 249\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 84.99798305768455 177.29442567567565 -0.16514867741462697\n",
      "ROBOT FOUND\n",
      "get_motor_meas 214 260\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 295.78583637269014 250.38023557258794 0.06374331253268685\n",
      "ROBOT FOUND\n",
      "get_motor_meas 257 266\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 308.7636459599941 249.08208650402867 0.105984357989599\n",
      "ROBOT FOUND\n",
      "get_motor_meas 246 248\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 99.9546606589693 182.87386792452827 -0.1853479499956945\n",
      "ROBOT FOUND\n",
      "get_motor_meas 270 240\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 325.62941781691364 249.06313227394807 0.10598435798959979\n",
      "ROBOT FOUND\n",
      "get_motor_meas 292 210\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 334.6901181823226 250.09572490706321 0.12970253715591204\n",
      "ROBOT FOUND\n",
      "get_motor_meas 252 253\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 118.95434591747146 181.27110294117648 -0.21866894587394262\n",
      "ROBOT FOUND\n",
      "get_motor_meas 266 223\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 353.1229540032181 250.09572490706321 0.12970253715591204\n",
      "ROBOT FOUND\n",
      "get_motor_meas 268 257\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 362.57282776090614 249.24339742044359 0.15431877592611964\n",
      "ROBOT FOUND\n",
      "get_motor_meas 258 232\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 373.4620019170204 248.58034403669726 0.17219081452293897\n",
      "ROBOT FOUND\n",
      "get_motor_meas 249 257\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 379.3437925518554 251.09881255535873 0.14784936525875492\n",
      "ROBOT FOUND\n",
      "get_motor_meas 233 241\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 389.1487349876224 248.7152276726793 0.1685969396094292\n",
      "ROBOT FOUND\n",
      "get_motor_meas 203 256\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 171.4398505165297 183.1179258594151 -0.22849663929186267\n",
      "ROBOT FOUND\n",
      "get_motor_meas 287 246\n",
      "ROBOT FOUND\n",
      "Camera Robot Position 405.4030430560052 254.19574093557787 0.14444157837464366\n"
     ]
    }
   ],
   "source": [
    "from Computer_vision import cv as com\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from Global_Nav import global_nav as gb\n",
    "\n",
    "WAIT_TIME = 0.2\n",
    "async def main():\n",
    "    #---- VIZUALIZATION PARAMETERS ----\n",
    "    # Set camera resolution\n",
    "    w = 1920\n",
    "    h = 1080\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, w)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, h)\n",
    "    cap.set(cv2.CAP_PROP_EXPOSURE, -7)\n",
    "    time.sleep(0.1)  # let the camera apply settings\n",
    "    \n",
    "    # Desired display size\n",
    "    display_width = 960\n",
    "    display_height = 540\n",
    "    \n",
    "    \n",
    "    #---- INITIALIZATION ---\n",
    "    ret, frame = cap.read()\n",
    "    matrix = com.matrix_perspective(frame)\n",
    "    transformed_frame = com.convert_perspective(frame, matrix)\n",
    "    \n",
    "    \n",
    "    global_map = com.get_map(transformed_frame)\n",
    "    robot = com.get_robot(transformed_frame)\n",
    "    #solved = global_map[:]\n",
    "    #FIND PATH\n",
    "    path = path = gb.a_star(global_map, robot[1], 0.35, \n",
    "                     (int(round(robot[0][1])), int(round(robot[0][0]))))\n",
    "    \n",
    "    #print(path)\n",
    "    #--- NAVIGATION PARAMETERS ---\n",
    "    \n",
    "    # params ekf\n",
    "    Ts = 0.1  # time step in seconds\n",
    "    L = 95  # distance between wheels in mm\n",
    "    speed_to_mms = 0.3375  # conversion factor from thymio speed units to mm/s from solution ex.8 \n",
    "    # Process noise for EKF (tune) (from model-mismatch/random-walk/control execution)\n",
    "    q_proc = (\n",
    "        1e-10, 1e-10, 1e-3,   # q_x, q_y, q_theta (model mismatch)\n",
    "        75.72,  0.002692,         # q_v_ctrl, q_omega_ctrl (control execution noise)\n",
    "        1e-2, 1e-5          # q_v_bias, q_omega_bias (random walk on v, omega)\n",
    "    )\n",
    "    # Camera measurement noise (tune)\n",
    "    r_cam = (1.435, 1.864, 0.001496)  # [mm^2, mm^2, rad^2]\n",
    "    r_mot = (75.72, 0.002692)    # motor noise on v, omega\n",
    "    \n",
    "    def pixel_to_world_mm(pos):\n",
    "        px, py = pos\n",
    "        x = 10 * px * (L / SIZE[1])\n",
    "        y = 10 * py * (81.3 / SIZE[0])\n",
    "        return x, y\n",
    "    \n",
    "    conv_x = 10 * (L / SIZE[1])\n",
    "    conv_y = 10 * (81.3 / SIZE[0])\n",
    "    # 1) buffers\n",
    "    traj = deque(maxlen=2000)   # (x,y)\n",
    "    # convert path!\n",
    "    waypoints = control.remove_collinear(control.grid_to_mm(path, cell_size_mm_x=conv_x, cell_size_mm_y=conv_y))\n",
    "    \n",
    "    # global obstacle repulsion map\n",
    "    # Build unknown cells list once per few cycles to save time\n",
    "    unk_cells = unknown_cells_world(global_map, conv_x/10, conv_y/10)\n",
    "    sleep_time = 7 # sleep in obstacle avoidance for this number of loops\n",
    "    loop_count = 0\n",
    "    \n",
    "    # --- INIT EKF----\n",
    "    #image = transformed_frame\n",
    "    pos, angle, __ = com.get_robot(transformed_frame)\n",
    "    pos = pixel_to_world_mm(pos)\n",
    "    x = pos[0]\n",
    "    y = pos[1]\n",
    "    x0=[x, y, angle,0,0]\n",
    "    ekf = filt.EKFState(x0, P0=1000*np.eye(5))\n",
    "    #print(ekf)\n",
    "    \n",
    "    # --- PLOTTING ---\n",
    "    ekf_traj = [] # for plot\n",
    "    # memory for plots\n",
    "    def ekf_get_state():\n",
    "        s = ekf.get_state()  # (x,y,theta)\n",
    "        ekf_traj.append((s[0], s[1], s[2]))  # log x,y each time it's called\n",
    "        return s\n",
    "    \n",
    "    \n",
    "    #---VISU---\n",
    "    for i in path : \n",
    "        global_map[i[0]][i[1]] = -4 # marker for path in my debug functions\n",
    "        \n",
    "    def draw_static_map(global_map, path):\n",
    "        # Choose a base canvas size matching your transformed frame\n",
    "        H, W = len(global_map), len(global_map[0])\n",
    "        \n",
    "        static = np.full((H, W, 3), 255, dtype=np.uint8)\n",
    "        \n",
    "        gm = np.asarray(global_map)\n",
    "        obst_y, obst_x = np.where(gm == -1)\n",
    "        static[obst_y, obst_x] = (0, 0, 255)  # BGR\n",
    "\n",
    "        # Optional: other map markers (e.g., -3 in blue)\n",
    "        extra_y, extra_x = np.where(gm == -3)\n",
    "        static[extra_y, extra_x] = (255, 0, 0)\n",
    "\n",
    "        # Path (green) drawn once\n",
    "        for (i, j) in path:\n",
    "            cv2.circle(static, (j, i), 2, (0, 255, 0), -1)\n",
    "\n",
    "        return static\n",
    "    \n",
    "    static_map_img = draw_static_map(global_map, path)\n",
    "    \n",
    "    drawing_robot_real = []\n",
    "    \n",
    "    #--- CONNECT TO THYMIO ---\n",
    "    try:\n",
    "        aw(node.lock()) # lock the node for R/W\n",
    "    except Exception:\n",
    "        pass # ignore it it wasn't locked\n",
    "    \n",
    "    aw(node.stop())\n",
    "    print(\"Connected:\", node)\n",
    "    motors = aw(node.wait_for_variables({\"motor.left.speed\",\"motor.right.speed\"}))\n",
    "    \n",
    "    \n",
    "    #--- HELPER FUNCTIONS FOR EKF --- \n",
    "    def get_motor_meas(): \n",
    "        # raw speeds in Thymio units (instantaneous)\n",
    "        vl = int(node.v.motor.left.speed)\n",
    "        vr = int(node.v.motor.right.speed)\n",
    "        #print(\"get_motor_meas\", vl, vr)\n",
    "        # convert to v [mm/s], omega [rad/s] \n",
    "        v, w = filt.motors_to_vw(vl, vr, speed_to_mms, L) \n",
    "        return np.array([v, w], dtype=float)\n",
    "    \n",
    "    def get_cam_meas(image=None):\n",
    "        # get position from camera\n",
    "        if image is not None:\n",
    "            pos, angle, Rob = com.get_robot(image)\n",
    "            #x = SIZE[1] - pos[0] \n",
    "            if Rob ==  False:\n",
    "                return None\n",
    "            pos = pixel_to_world_mm(pos)\n",
    "            x = pos[0]\n",
    "            y = pos[1]\n",
    "            #print(\"Camera Robot Position\", x, y, angle)\n",
    "            return np.array([x, y, angle], dtype=float)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    \n",
    "    obstacle_not_passed = False\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        #--- GET IMAGE ---\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "    \n",
    "        # Apply perspective transform\n",
    "        transformed_frame = com.convert_perspective(frame, matrix)\n",
    "        transformed_frame_visu = transformed_frame.copy() \n",
    "        # transformed_frame = current image we can work with\n",
    "    \n",
    "    \n",
    "        #--- VISU ---\n",
    "        # Start from cached static image (cheap copy)\n",
    "        vis = static_map_img.copy()\n",
    "\n",
    "        # Overlay dynamic info\n",
    "        robot_px, robot_py, found = None, None, False\n",
    "        robot, angle, found = com.get_robot(transformed_frame)\n",
    "\n",
    "        if found:\n",
    "            # Draw robot arrow\n",
    "            length = 20\n",
    "            p0 = (int(robot[0]), int(robot[1]))\n",
    "            p1 = (int(robot[0] + length*np.cos(angle)),\n",
    "                int(robot[1] + length*np.sin(angle)))\n",
    "            cv2.arrowedLine(vis, p0, p1, color=(20, 20, 20), thickness=2, tipLength=0.3)\n",
    "            \n",
    "            drawing_robot_real.append(p0)\n",
    "            \n",
    "            \n",
    "            #found = False\n",
    "            \n",
    "        for i in range(len(drawing_robot_real)):\n",
    "                robot1 = drawing_robot_real[i]\n",
    "                \n",
    "                #end_point = drawing_robot_real[i][1]\n",
    "                cv2.circle(vis, robot1, 2, (0,0,255), -1)\n",
    "                \n",
    "        # Optional: show a status message\n",
    "        \n",
    "\n",
    "        H, W = vis.shape[:2]\n",
    "        box_h = 48 # banner height in pixels \n",
    "        y0 = H - box_h\n",
    "        status_overlay = vis.copy()\n",
    "        cv2.rectangle(status_overlay, (0, y0), (W, H), (255, 255, 255), thickness=-1) # white bar\n",
    "        vis = cv2.addWeighted(status_overlay, 0.6, vis, 0.4, 0.0)\n",
    "        msgs = []\n",
    "        if found : msgs.append((\"Robot Found\", (0, 128, 0))) # green \n",
    "        if obstacle_not_passed: msgs.append((\"Local obstacle detected\", (0, 0, 255))) # red\n",
    "        x_text = 16 \n",
    "        y_text = y0 + 30 # baseline inside the bar \n",
    "        for k, (msg, color) in enumerate(msgs):\n",
    "            cv2.putText(vis, msg, (x_text + 250*k, y_text), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Display\n",
    "        #overlay = static_map_img\n",
    "        #alpha_overlay = 0.6 \n",
    "        #vis = cv2.addWeighted(transformed_frame, 1.0, overlay, alpha_overlay, 0.0)\n",
    "        cv2.imshow(\"Transformed Camera Feed\", cv2.resize(vis, (display_width, display_height)))\n",
    "        \n",
    "    \n",
    "        #--- Camera Window ---\n",
    "        # Show the transformed frame live\n",
    "        small_transformed = cv2.resize(transformed_frame_visu, (display_width, display_height))\n",
    "        cv2.imshow(\"Transformed Camera\", small_transformed)\n",
    "    \n",
    "        # Resize for display only\n",
    "        small_frame = cv2.resize(frame, (display_width, display_height))\n",
    "    \n",
    "        # Show the live frame\n",
    "        cv2.imshow(\"Live Camera Feed\", small_frame)\n",
    "        \n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            aw(node.set_variables({\"motor.left.target\":[0], \"motor.right.target\":[0]}))\n",
    "            aw(node.unlock())\n",
    "            break\n",
    "    \n",
    "        \n",
    "        #--- GlOBAL NAVIGATION ---\n",
    "         # final loop\n",
    "        if waypoints :\n",
    "            # get motion params\n",
    "            vl_cmd, vr_cmd = control.get_cmd()\n",
    "            z_mot= get_motor_meas()\n",
    "            z_cam = get_cam_meas(transformed_frame)\n",
    "            \n",
    "            # EKF STEP\n",
    "            ekf.step(vl_cmd, vr_cmd, z_cam, r_cam=r_cam, z_mot=z_mot, r_mot=r_mot, Ts=Ts, q_proc=q_proc)\n",
    "            #print(\"ekf results:\", ekf.x, ekf.P)\n",
    "            state = ekf_get_state()\n",
    "            # motion control\n",
    "            #print(\"waypoints:\", waypoints)\n",
    "            \n",
    "            #--- LOCAL AVOIDANCE --- \n",
    "            if not(ln.prox_less_threshold(list(node[\"prox.horizontal\"][:5]), 1500)) or obstacle_not_passed :\n",
    "                #print(\"here\")\n",
    "                #print((list(node[\"prox.horizontal\"][:5]), 700))\n",
    "                objectif = (waypoints[0][0]/10, waypoints[0][1]/10) \n",
    "                curr_dir = (100*m.cos(state[2]), 100*m.sin(state[2]))\n",
    "                curr_pos = (state[0]/10, state[1]/10)\n",
    "                obstacle_not_passed = True\n",
    "                await node.wait_for_variables({\"prox.horizontal\"})\n",
    "                prox_read = list(node[\"prox.horizontal\"])\n",
    "                \n",
    "    \n",
    "                #--- TEST IF OBSTACLED IS PASSED ---\n",
    "                if (ln.prox_less_threshold(prox_read, 1000)) and obstacle_not_passed:\n",
    "                    #print(\"PASSED\")\n",
    "                    aw(control.set_motors(node,100,100))\n",
    "                    #await client.sleep(1.5)\n",
    "                    if loop_count > sleep_time:  # non blocking sleep time (to get camera and filter updates)\n",
    "                        obstacle_not_passed = False\n",
    "                        loop_count = 0\n",
    "                    loop_count += loop_count\n",
    "                    \n",
    "                    while waypoints and dist_mm((state[0], state[1]), waypoints[0]) < thresh:\n",
    "                        waypoints.pop(0)\n",
    "                    #waypoints = maybe_pop_waypoint(state, last_state, waypoints, pos_tol_mm=50.0)\n",
    "                    continue\n",
    "                \n",
    "                vect = ln.vect_calculation(objectif, (curr_pos),curr_dir,  prox_read[:5], 150, debug=False)\n",
    "                # added for global obstacles\n",
    "                # Unknown repulsion:\n",
    "                ux, uy = add_unknown_repulsion(curr_pos, unk_cells, UNKNOWN_WEIGHT=0.25, p=1.0, max_range=15.0)\n",
    "                # Combine:\n",
    "                vect = (vect[0] - ux, vect[1] - uy)\n",
    "                #\n",
    "                angle_command = m.atan2(vect[1], vect[0])\n",
    "                delta_speed = np.sign(angle_command)*min(abs(angle_command/WAIT_TIME*800/m.pi), 300)\n",
    "                left_speed = int(100+(delta_speed/2))\n",
    "                right_speed = int(100-(delta_speed/2))\n",
    "                aw(control.set_motors(node, left=left_speed, right=right_speed))\n",
    "                #print(f\" curr_pos = ({curr_pos[0]:.2f}, {curr_pos[1]:.2f}), vect = {angle_command:.2f} and delta_speed = {delta_speed:.2f}, curr_dir = ({curr_dir[0]:.2f}, {curr_dir[1]:.2f})\")\n",
    "                await client.sleep(ln.WAIT_TIME)\n",
    "                continue\n",
    "                #print(curr_dir, delta_speed*WAIT_TIME*m.pi/100, m.cos(delta_speed*WAIT_TIME*m.pi/100)\n",
    "    \n",
    "            #--- FOLLOW THE GLOBAL PATH ---\n",
    "            obstacle_not_passed = False\n",
    "            waypoints = aw(control.follow_path(node, state, waypoints, v_cmd=250, kp_heading=90.0,\n",
    "                          pos_tol=12.0))\n",
    "        else : \n",
    "            aw(node.set_variables({\"motor.left.target\":[0], \"motor.right.target\":[0]}))\n",
    "            aw(node.unlock())\n",
    "            \n",
    "    \n",
    "        # quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            aw(node.set_variables({\"motor.left.target\":[0], \"motor.right.target\":[0]}))\n",
    "            aw(node.unlock())\n",
    "            break\n",
    "    \n",
    "\n",
    "# run main\n",
    "aw(main())\n",
    "\n",
    "# Release resources\n",
    "#cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18631dec",
   "metadata": {},
   "source": [
    "![final path with camera frame, converted map frame and path plan/execution frame](pathtest.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
