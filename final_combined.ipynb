{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1d6cbe-34fb-4d14-8bd2-3ec508687171",
   "metadata": {},
   "source": [
    "# **Basics of Mobile robotics**\n",
    "### **Project**\n",
    "\n",
    "**Paul Huot-Marchand** \n",
    "**Luca Seelbach**\n",
    "**Manuela Waible** \n",
    " \n",
    "\n",
    "**Date:** *2025*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452e01e-bf14-476a-8c23-de648cc0d372",
   "metadata": {},
   "source": [
    "# **INTRODUCTION**\n",
    "Our project take place on a rectangular white environment with black obstacles of any shapes a black circle as goal and a  black isocele triangle on the robot. The goal was to implement global navigation using the camera provided creating a global occupancy map, then applying an A* algorithm to find an optimized path. A filter was implemented to track position of the robot. Local avoidance was implemented to avoid la minuit added obstacles using thymio infrared sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695b99c1-9b64-40b0-a859-30c1c6860de8",
   "metadata": {},
   "source": [
    "## **I Computer Vision**\n",
    "The steps of our computer vision part is as follow : \n",
    "- Detect the environment,\n",
    "- Correct percpective,\n",
    "- detect obstacles and goal to fill occupancy map\n",
    "- detect the robot\n",
    "\n",
    "To do so a general filtering framework was adopted. First convert to gray scale, apply bilateral filter to enhance edge and remove noise, apply canny filter to detect edges, apply morphological filter to close as much as possib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c4f2938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tdmclient in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (0.1.21)\n",
      "Requirement already satisfied: numpy in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (1.16.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: tqdm in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: websockets in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (from tdmclient) (15.0.1)\n",
      "Requirement already satisfied: zeroconf in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (from tdmclient) (0.147.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: ifaddr>=0.1.7 in c:\\users\\manuela\\anaconda3\\envs\\mobrob\\lib\\site-packages (from zeroconf->tdmclient) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tdmclient numpy scipy opencv-python tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec37acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import cv2\n",
    "import tqdm\n",
    "from Computer_vision import cv as com\n",
    "#import Filtering as flt \n",
    "from Global_Nav import global_nav as gb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math as m\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from Filtering import Control_fromEKF as control\n",
    "from Filtering import Filtering as filt\n",
    "from Local_Nav import local_nav as ln\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95ae813b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node 7e5a04de-7cbe-4397-8545-f33016b69c2f"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate the communication between the Thymio and the computer\n",
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "\n",
    "node = await client.wait_for_node()\n",
    "await node.lock() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fffa2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to stop it\n",
    "aw(node.set_variables({\"motor.left.target\":[0], \"motor.right.target\":[0]}))\n",
    "aw(node.unlock())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b801d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_real_to_pixel(length_cm, env_size_cm, map_size):\n",
    "    \n",
    "    L, W = env_size_cm\n",
    "    height, width = map_size\n",
    "    \n",
    "    # scale factors\n",
    "    scale_x = width / L\n",
    "    scale_y = height / W\n",
    "    \n",
    "    # average scale for uniform scaling\n",
    "    scale = (scale_x + scale_y) / 2\n",
    "    \n",
    "    return length_cm * scale\n",
    "\n",
    "#================HYPERPARAMETESRS======================\n",
    "\n",
    "#SiZE OF THE ENVIRONEMENT (cm)\n",
    "L = 113.5\n",
    "W = 81.3\n",
    "Ratio = L/W\n",
    "\n",
    "#SiZE IN PIXEL OF THE CORRECTED MAP\n",
    "Y_res = 480\n",
    "SIZE = [Y_res, int(Y_res*Ratio)]\n",
    "\n",
    "#SIZE OF THE TRIANGLE (cm)\n",
    "L_T = 10\n",
    "H_T = 3.5\n",
    "L_T_p = length_real_to_pixel(L_T,[L,W], SIZE)\n",
    "H_T_p = length_real_to_pixel(H_T,[L,W], SIZE)\n",
    "\n",
    "#SIZE OF THE GOAL (cm)\n",
    "R_G = 8.4/2\n",
    "\n",
    "R_G_p = length_real_to_pixel(R_G,[L,W], SIZE)\n",
    "\n",
    "# AREA RATIO\n",
    "RATIO_T = (L_T*H_T/2) / (L*W) \n",
    "\n",
    "#FILTERING PARAMETERS FOR THE ORIGINAL IMAGE\n",
    "B1_O = 5\n",
    "B2_O = 50\n",
    "B3_O = 50\n",
    "C1_O = 0.5\n",
    "C2_O = 1.5\n",
    "M1_O = 8\n",
    "CL1_O = 2.0\n",
    "M_O = 5\n",
    "D_O = 5\n",
    "\n",
    "#FILTERING PARAMETERS FOR THE CORRECTED IMAGE\n",
    "B1_C = 8\n",
    "B2_C = 70\n",
    "B3_C = 70\n",
    "C1_C = 0.4\n",
    "C2_C = 1.6\n",
    "M1_C = 5\n",
    "CL1_C = 4.0\n",
    "M_C = 5\n",
    "D_C = 5\n",
    "\n",
    "#FILTERING PARAMETERS FOR ROBOT DETECTION\n",
    "B1_T = 5\n",
    "B2_T = 80\n",
    "B3_T = 80\n",
    "C1_T = 0.4\n",
    "C2_T = 1.6\n",
    "M1_T = 5\n",
    "CL1_T = 2\n",
    "M_T = 2\n",
    "D_T = 2\n",
    "\n",
    "\n",
    "#PARAMETERS TO DETECT THE ENV\n",
    "#Min_area_env = 1920*1080*0.01   #Min area in pixel of the env\n",
    "Min_area_env = 1000\n",
    "Env_approx = 0.1\n",
    "\n",
    "#PARAMETERS TO DETECT THE OBSTACLES\n",
    "Min_area_obs = SIZE[0]*SIZE[1]*0.005   #Min area in pixel of the env\n",
    "Max_area_obs = SIZE[0]*SIZE[1]*0.5   #Max area in pixel of the env\n",
    "Obs_approx = 0.01\n",
    "\n",
    "#PARAMETERS TO DETECT GOAL\n",
    "Min_area_goal = np.pi * R_G_p * R_G_p *0.8\n",
    "Max_area_goal = np.pi * R_G_p * R_G_p * 1.8\n",
    "\n",
    "#PARAMETERS TO DETECT THE ROBOT\n",
    "Min_area_rob = (L_T_p*H_T_p /2) * 0.2   #Min area in pixel of the env\n",
    "Max_area_rob =  (L_T_p*H_T_p /2) * 1.8\n",
    "Rob_approx = 0.08\n",
    "\n",
    "#ROBOT CARACTERISTICS\n",
    "R_ROBOT = 6\n",
    "R_ROBOT_p = length_real_to_pixel(R_ROBOT,[L,W], SIZE)\n",
    "\n",
    "\n",
    "#SYMBOLS FOR THE MAP\n",
    "FREE_SPACE = 0\n",
    "OCCUPIED_SPACE = -1\n",
    "GOAL = -3\n",
    "\n",
    "DEBUG = False\n",
    "#========================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87e035f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e8a7bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to camera\n",
    "\n",
    "if DEBUG : \n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "#GLOBAL FRAMEWORK TO USE VISION\n",
    "#EXECUTE CELL ABOVE WITH DEBUG = TRUE FOR TUNING UNTIL EVERYTHING IS CORRECTLY FILTERED AND FOUND\n",
    "cap = cv2.VideoCapture(1)\n",
    "    \n",
    "if not cap.isOpened():\n",
    "    print(\"Could not access webcam\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "496cd18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBOT FOUND\n",
      "MAP ANALYZED : \n",
      "GOAL FOUND\n",
      "ROBOT FOUND\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#INITIALIZATION\n",
    "#GET A FRAME\n",
    "img = com.get_picture_optimized(cap)\n",
    "#img = cv2.imread(\"02.png\")\n",
    "#COMPUTE TRANSFORMATION MATRIX\n",
    "matrix = com.matrix_perspective(img)\n",
    "#CORRECT IMAGE\n",
    "transformed_image = com.convert_perspective(img,matrix)\n",
    "\n",
    "#PLOTTING\n",
    "if DEBUG: \n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Perspective Corrected Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#GET GLOBAL MAP\n",
    "global_map = com.get_map(transformed_image)\n",
    "\n",
    "#GET ROBOT POSITION AND ORIENTATION\n",
    "robot = com.get_robot(transformed_image)\n",
    "\n",
    "\n",
    "length = 100\n",
    "end_x = int(robot[0][0] + length * np.cos(robot[1]))\n",
    "end_y = int(robot[0][1] + length * np.sin(robot[1]))\n",
    "end_point = (end_x, end_y)\n",
    "global_map4plot = global_map.copy()\n",
    "cv2.arrowedLine(global_map4plot, [int(robot[0][0]), int(robot[0][1])], end_point, color=(2, 2, 2), thickness=10)\n",
    "plt.imshow(global_map4plot)\n",
    "plt.show()\n",
    "if DEBUG : \n",
    "    global_map4plot = global_map.copy()\n",
    "    cv2.arrowedLine(global_map4plot, robot[0], end_point, color=(2, 2, 2), thickness=10)\n",
    "    plt.imshow(global_map4plot)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda900a5-037e-4ee5-9b5f-32913256fcef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4cad93f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "670\n",
      "158\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "global_map = global_map.astype(int)\n",
    "solved = global_map[:]\n",
    "path = path = gb.a_star(global_map, robot[1], 0.25, \n",
    "                 (int(round(robot[0][1])), int(round(robot[0][0]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0455a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help functions \n",
    "# Utility to pop waypoint if we pass it by local obstacle avoidance\n",
    "thresh = 120\n",
    "def dist_mm(p, q):\n",
    "    return float(np.hypot(p[0] - q[0], p[1] - q[1]))\n",
    "\n",
    "# Utilities to add global obstacles to repulsion vector in local obstacle avoidance\n",
    "EPSILON = 1e-2\n",
    "def add_unknown_repulsion(curr_pos, unknown_cells, UNKNOWN_WEIGHT=0.5, p=1.0, max_range=15.0):\n",
    "    \"\"\"\n",
    "    curr_pos: (x_cm, y_cm)\n",
    "    unknown_cells: iterable of (x_cm, y_cm) of the centers of -1 cells\n",
    "    UNKNOWN_WEIGHT: small global weight\n",
    "    p: distance power for attenuation\n",
    "    max_range: ignore far unknowns (cm) to limit computation/noise\n",
    "    \"\"\"\n",
    "    rx, ry = curr_pos\n",
    "    ux, uy = 0.0, 0.0\n",
    "    for cx, cy in unknown_cells:\n",
    "        dx = rx - cx\n",
    "        dy = ry - cy\n",
    "        d = m.hypot(dx, dy)\n",
    "        if d < 1e-6 or d > max_range:\n",
    "            continue\n",
    "        # unit vector from cell to robot\n",
    "        ux += (dx / d) * (1.0 / ((d + EPSILON)**p))\n",
    "        uy += (dy / d) * (1.0 / ((d + EPSILON)**p))\n",
    "    return (UNKNOWN_WEIGHT * ux, UNKNOWN_WEIGHT * uy)\n",
    "\n",
    "def unknown_cells_world(grid, cell_size_cm_x, cell_size_cm_y):\n",
    "    \"\"\"\n",
    "    Turn indices of -1 cells into world coordinates (cm).\n",
    "    origin_world_cm: (x0_cm, y0_cm) of grid cell (0,0)\n",
    "    res_cm: cell size (cm)\n",
    "    \"\"\"\n",
    "    x0, y0 = (0, 0)\n",
    "    cells = []\n",
    "    H, W = len(grid), len(grid[0])\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            if grid[i][j] == -1:\n",
    "                cx = x0 + (j + 0.5) * cell_size_cm_x\n",
    "                cy = y0 + (i + 0.5) * cell_size_cm_y\n",
    "                cells.append((cx, cy))\n",
    "    return cells\n",
    "\n",
    "\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "65c589ca-efaf-4c45-b496-9c4d14dc603a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBOT FOUND\n",
      "MAP ANALYZED : \n",
      "GOAL FOUND\n",
      "ROBOT FOUND\n",
      "480\n",
      "670\n",
      "397\n",
      "618\n",
      "294909\n",
      "ROBOT FOUND\n",
      "Connected: Node 7e5a04de-7cbe-4397-8545-f33016b69c2f\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[0, 0, 2467, 0, 0]\n",
      "angle to abjectif :  0.018456750908610313\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[0, 0, 2883, 0, 0]\n",
      "angle to abjectif :  -0.10700282598082386\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[0, 0, 4271, 0, 0]\n",
      "angle to abjectif :  -0.4547620601401793\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[0, 3984, 4307, 0, 0]\n",
      "angle to abjectif :  -1.1350070295681927\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[4100, 0, 0, 0, 0]\n",
      "angle to abjectif :  -1.5429756235814973\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[4100, 0, 0, 0, 0]\n",
      "angle to abjectif :  -1.7889014376999517\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[0, 0, 0, 0, 0]\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[1961, 0, 0, 0, 0]\n",
      "angle to abjectif :  -0.6476744286451284\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[0, 2983, 0, 0, 0]\n",
      "angle to abjectif :  -0.3549927139297573\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[0, 1999, 1513, 0, 0]\n",
      "angle to abjectif :  -0.19435853278271165\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[0, 0, 2894, 0, 0]\n",
      "angle to abjectif :  -0.24488996647685088\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[0, 4290, 0, 0, 0]\n",
      "angle to abjectif :  -0.43332070623005287\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[4091, 3883, 0, 0, 0]\n",
      "angle to abjectif :  -0.47315523997456715\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[3900, 4285, 0, 0, 0]\n",
      "angle to abjectif :  -0.6946162059191308\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[4186, 0, 0, 0, 0]\n",
      "angle to abjectif :  -1.0211735670498927\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[0, 0, 0, 0, 0]\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[0, 1710, 0, 0, 0]\n",
      "angle to abjectif :  -0.3118983572036683\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[0, 2186, 1450, 0, 0]\n",
      "angle to abjectif :  -0.2655869906181038\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[1346, 2087, 1464, 0, 0]\n",
      "angle to abjectif :  -0.5812203557347023\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[0, 0, 0, 0, 0]\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[1504, 0, 0, 0, 0]\n",
      "angle to abjectif :  -0.5094081252314143\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[2642, 0, 0, 0, 0]\n",
      "angle to abjectif :  -0.5114224718984179\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[0, 0, 0, 0, 0]\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "kidnapped\n",
      "[124 109]\n",
      "kidnapped\n",
      "[124 109]\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "kidnapped\n",
      "[114 123]\n",
      "kidnapped\n",
      "[114 123]\n",
      "NO ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "kidnapped\n",
      "[114 123]\n",
      "kidnapped\n",
      "[114 123]\n",
      "NO ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "kidnapped\n",
      "[110 130]\n",
      "kidnapped\n",
      "[110 130]\n",
      "NO ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "kidnapped\n",
      "[116 127]\n",
      "kidnapped\n",
      "[116 127]\n",
      "NO ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "kidnapped\n",
      "[101 109]\n",
      "kidnapped\n",
      "[101 109]\n",
      "NO ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "kidnapped\n",
      "[127  91]\n",
      "kidnapped\n",
      "[127  91]\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "kidnapped\n",
      "[129 162]\n",
      "kidnapped\n",
      "[129 162]\n",
      "NO ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "kidnapped\n",
      "[119 128]\n",
      "kidnapped\n",
      "[119 128]\n",
      "NO ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "kidnapped\n",
      "[119 128]\n",
      "kidnapped\n",
      "[119 128]\n",
      "NO ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "kidnapped\n",
      "[104 120]\n",
      "kidnapped\n",
      "[104 120]\n",
      "NO ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "kidnapped\n",
      "[104 120]\n",
      "kidnapped\n",
      "[104 120]\n",
      "NO ROBOT FOUND\n",
      "NO ROBOT FOUND\n",
      "kidnapped\n",
      "[ 98 117]\n",
      "kidnapped\n",
      "[ 98 117]\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[2583, 0, 0, 0, 0]\n",
      "angle to abjectif :  1.6049112609908347\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[3481, 0, 0, 0, 0]\n",
      "angle to abjectif :  1.7563287031593693\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "here\n",
      "[0, 0, 0, 0, 0]\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n",
      "ROBOT FOUND\n"
     ]
    }
   ],
   "source": [
    "from Computer_vision import cv as com\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from Global_Nav import global_nav as gb\n",
    "\n",
    "WAIT_TIME = 0.2\n",
    "async def main():\n",
    "    #---- VIZUALIZATION PARAMETERS ----\n",
    "    # Set camera resolution\n",
    "    w = 1920\n",
    "    h = 1080\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, w)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, h)\n",
    "    cap.set(cv2.CAP_PROP_EXPOSURE, -7)\n",
    "    time.sleep(0.1)  # let the camera apply settings\n",
    "    \n",
    "    # Desired display size\n",
    "    display_width = 960\n",
    "    display_height = 540\n",
    "    \n",
    "    \n",
    "    #---- INITIALIZATION ---\n",
    "    ret, frame = cap.read()\n",
    "    matrix = com.matrix_perspective(frame)\n",
    "    transformed_frame = com.convert_perspective(frame, matrix)\n",
    "    \n",
    "    \n",
    "    global_map = com.get_map(transformed_frame)\n",
    "    robot = com.get_robot(transformed_frame)\n",
    "    #solved = global_map[:]\n",
    "    #FIND PATH\n",
    "    scaling = 0.3\n",
    "    path = path = gb.a_star(global_map, robot[1], scaling, \n",
    "                     (int(round(robot[0][1])), int(round(robot[0][0]))))\n",
    "    \n",
    "    #print(path)\n",
    "    #--- NAVIGATION PARAMETERS ---\n",
    "    \n",
    "    # params ekf\n",
    "    Ts = 0.1  # time step in seconds\n",
    "    L = 95  # distance between wheels in mm\n",
    "    speed_to_mms = 0.3375  # conversion factor from thymio speed units to mm/s from solution ex.8 \n",
    "    # Process noise for EKF (tune) (from model-mismatch/random-walk/control execution)\n",
    "    q_proc = (\n",
    "        1e-10, 1e-10, 1e-3,   # q_x, q_y, q_theta (model mismatch)\n",
    "        75.72,  0.002692,         # q_v_ctrl, q_omega_ctrl (control execution noise)\n",
    "        1e-2, 1e-5          # q_v_bias, q_omega_bias (random walk on v, omega)\n",
    "    )\n",
    "    # Camera measurement noise (tune)\n",
    "    r_cam = (1.435, 1.864, 0.001496)  # [mm^2, mm^2, rad^2]\n",
    "    r_mot = (75.72, 0.002692)    # motor noise on v, omega\n",
    "    \n",
    "    def pixel_to_world_mm(pos):\n",
    "        px, py = pos\n",
    "        x = 10 * px * (L / SIZE[1])\n",
    "        y = 10 * py * (81.3 / SIZE[0])\n",
    "        return x, y\n",
    "    \n",
    "    conv_x = 10 * (L / SIZE[1])\n",
    "    conv_y = 10 * (81.3 / SIZE[0])\n",
    "    # 1) buffers\n",
    "    traj = deque(maxlen=2000)   # (x,y)\n",
    "    # convert path!\n",
    "    waypoints = control.remove_collinear(control.grid_to_mm(path, cell_size_mm_x=conv_x, cell_size_mm_y=conv_y))\n",
    "    step_count = 0\n",
    "    kidnap_first = False\n",
    "    kidnap_second = False\n",
    "    # kidnapping help function\n",
    "    async def test_kidnap():\n",
    "        kidnap_thresh = 500  # off ground\n",
    "        # Kidnap check\n",
    "        if np.mean(np.array(node[\"prox.ground.delta\"][:])) < kidnap_thresh :\n",
    "            print(\"kidnapped\")\n",
    "            print(np.array(node[\"prox.ground.delta\"][:]))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def update_kidnap(waypoints, ekf_traj):\n",
    "        # Compute distances between last three positions\n",
    "        p1 = ekf_traj[-1][0:2]\n",
    "        p2 = ekf_traj[-2][0:2]\n",
    "        # Compute midpoint of the pair that gave the min distance\n",
    "        mean = ((p1[0] + p2[0]) / 2, (p1[1] + p2[1]) / 2)\n",
    "        # compute distances to waypoints\n",
    "        distance_waypoints = [dist_mm(mean, wps) for wps in waypoints]\n",
    "        min_index = np.argmin(distance_waypoints)\n",
    "        return min_index\n",
    "            \n",
    "    # global obstacle repulsion map\n",
    "    # Build unknown cells list once per few cycles to save time\n",
    "    unk_cells = unknown_cells_world(global_map, conv_x/10, conv_y/10)\n",
    "    #sleep_time = 1 # sleep in obstacle avoidance for this number of loops\n",
    "    #loop_count = 0\n",
    "    \n",
    "    # --- INIT EKF----\n",
    "    #image = transformed_frame\n",
    "    pos, angle, __ = com.get_robot(transformed_frame)\n",
    "    pos = pixel_to_world_mm(pos)\n",
    "    x = pos[0]\n",
    "    y = pos[1]\n",
    "    x0=[x, y, angle,0,0]\n",
    "    ekf = filt.EKFState(x0, P0=1000*np.eye(5))\n",
    "    #print(ekf)\n",
    "    \n",
    "    # --- PLOTTING ---\n",
    "    ekf_traj = [] # for plot\n",
    "    # memory for plots\n",
    "    def ekf_get_state():\n",
    "        s = ekf.get_state()  # (x,y,theta)\n",
    "        ekf_traj.append((s[0], s[1], s[2]))  # log x,y each time it's called\n",
    "        return s\n",
    "    \n",
    "    \n",
    "    #---VISU---\n",
    "    for i in path : \n",
    "        global_map[i[0]][i[1]] = -4 # marker for path in my debug functions\n",
    "        \n",
    "    def draw_static_map(global_map, path):\n",
    "        # Choose a base canvas size matching your transformed frame\n",
    "        H, W = len(global_map), len(global_map[0])\n",
    "        \n",
    "        static = np.full((H, W, 3), 255, dtype=np.uint8)\n",
    "        \n",
    "        grown_map = gb.obstacle_scale(global_map.copy(), scaling)\n",
    "        gm = np.asarray(grown_map)\n",
    "        obst_y, obst_x = np.where(gm == -1)\n",
    "        static[obst_y, obst_x] = (0, 255, 255)\n",
    "        \n",
    "        gm = np.asarray(global_map)\n",
    "        obst_y, obst_x = np.where(gm == -1)\n",
    "        static[obst_y, obst_x] = (0, 0, 255)  # BGR\n",
    "\n",
    "        # Optional: other map markers (e.g., -3 in blue)\n",
    "        extra_y, extra_x = np.where(gm == -3)\n",
    "        static[extra_y, extra_x] = (255, 0, 0)\n",
    "\n",
    "        # Path (green) drawn once\n",
    "        for (i, j) in path:\n",
    "            cv2.circle(static, (j, i), 2, (0, 255, 0), -1)\n",
    "\n",
    "        return static\n",
    "    \n",
    "    static_map_img = draw_static_map(global_map, path)\n",
    "    \n",
    "    drawing_robot_real = []\n",
    "    \n",
    "    #--- CONNECT TO THYMIO ---\n",
    "    try:\n",
    "        aw(node.lock()) # lock the node for R/W\n",
    "    except Exception:\n",
    "        pass # ignore it it wasn't locked\n",
    "    \n",
    "    aw(node.stop())\n",
    "    print(\"Connected:\", node)\n",
    "    motors = aw(node.wait_for_variables({\"motor.left.speed\",\"motor.right.speed\"}))\n",
    "    \n",
    "    \n",
    "    #--- HELPER FUNCTIONS FOR EKF --- \n",
    "    def get_motor_meas(): \n",
    "        # raw speeds in Thymio units (instantaneous)\n",
    "        vl = int(node.v.motor.left.speed)\n",
    "        vr = int(node.v.motor.right.speed)\n",
    "        #print(\"get_motor_meas\", vl, vr)\n",
    "        # convert to v [mm/s], omega [rad/s] \n",
    "        v, w = filt.motors_to_vw(vl, vr, speed_to_mms, L) \n",
    "        return np.array([v, w], dtype=float)\n",
    "    \n",
    "    def get_cam_meas(image=None):\n",
    "        # get position from camera\n",
    "        if image is not None:\n",
    "            pos, angle, Rob = com.get_robot(image)\n",
    "            #x = SIZE[1] - pos[0] \n",
    "            if Rob ==  False:\n",
    "                return None\n",
    "            pos = pixel_to_world_mm(pos)\n",
    "            x = pos[0]\n",
    "            y = pos[1]\n",
    "            #print(\"Camera Robot Position\", x, y, angle)\n",
    "            return np.array([x, y, angle], dtype=float)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    \n",
    "    obstacle_not_passed = False\n",
    "    stop = False\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        #--- GET IMAGE ---\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "    \n",
    "        # Apply perspective transform\n",
    "        transformed_frame = com.convert_perspective(frame, matrix)\n",
    "        transformed_frame_visu = transformed_frame.copy() \n",
    "        # transformed_frame = current image we can work with\n",
    "    \n",
    "    \n",
    "        #--- VISU ---\n",
    "        # Start from cached static image (cheap copy)\n",
    "        vis = static_map_img.copy()\n",
    "\n",
    "        # Overlay dynamic info\n",
    "        robot_px, robot_py, found = None, None, False\n",
    "        robot, angle, found = com.get_robot(transformed_frame)\n",
    "\n",
    "        if found:\n",
    "            # Draw robot arrow\n",
    "            length = 20\n",
    "            p0 = (int(robot[0]), int(robot[1]))\n",
    "            p1 = (int(robot[0] + length*np.cos(angle)),\n",
    "                int(robot[1] + length*np.sin(angle)))\n",
    "            cv2.arrowedLine(vis, p0, p1, color=(20, 20, 20), thickness=2, tipLength=0.3)\n",
    "            \n",
    "            drawing_robot_real.append(p0)\n",
    "            \n",
    "            \n",
    "            #found = False\n",
    "            \n",
    "        for i in range(len(drawing_robot_real)):\n",
    "                robot1 = drawing_robot_real[i]\n",
    "                \n",
    "                #end_point = drawing_robot_real[i][1]\n",
    "                cv2.circle(vis, robot1, 2, (0,0,255), -1)\n",
    "                \n",
    "        # Optional: show a status message\n",
    "        \n",
    "\n",
    "        H, W = vis.shape[:2]\n",
    "        box_h = 48 # banner height in pixels \n",
    "        y0 = H - box_h\n",
    "        status_overlay = vis.copy()\n",
    "        cv2.rectangle(status_overlay, (0, y0), (W, H), (255, 255, 255), thickness=-1) # white bar\n",
    "        vis = cv2.addWeighted(status_overlay, 0.6, vis, 0.4, 0.0)\n",
    "        msgs = []\n",
    "        if found : msgs.append((\"Robot Found\", (0, 128, 0))) # green \n",
    "        if obstacle_not_passed: msgs.append((\"Local obstacle detected\", (0, 0, 255))) # red\n",
    "        if kidnap_first: msgs.append((\"KIDNAPPED\", (0, 0, 255)))\n",
    "        x_text = 16 \n",
    "        y_text = y0 + 30 # baseline inside the bar \n",
    "        for k, (msg, color) in enumerate(msgs):\n",
    "            cv2.putText(vis, msg, (x_text + 250*k, y_text), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Display\n",
    "        #overlay = static_map_img\n",
    "        #alpha_overlay = 0.6 \n",
    "        #vis = cv2.addWeighted(transformed_frame, 1.0, overlay, alpha_overlay, 0.0)\n",
    "        cv2.imshow(\"Transformed Camera Feed\", cv2.resize(vis, (display_width, display_height)))\n",
    "        \n",
    "    \n",
    "        #--- Camera Window ---\n",
    "        # Show the transformed frame live\n",
    "        small_transformed = cv2.resize(transformed_frame_visu, (display_width, display_height))\n",
    "        cv2.imshow(\"Transformed Camera\", small_transformed)\n",
    "    \n",
    "        # Resize for display only\n",
    "        small_frame = cv2.resize(frame, (display_width, display_height))\n",
    "    \n",
    "        # Show the live frame\n",
    "        cv2.imshow(\"Live Camera Feed\", small_frame)\n",
    "        \n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            aw(node.set_variables({\"motor.left.target\":[0], \"motor.right.target\":[0]}))\n",
    "            aw(node.unlock())\n",
    "            break\n",
    "    \n",
    "        \n",
    "        #--- GlOBAL NAVIGATION ---\n",
    "         # final loop\n",
    "        if step_count < len(waypoints):\n",
    "            # get motion params\n",
    "            vl_cmd, vr_cmd = control.get_cmd()\n",
    "            z_mot= get_motor_meas()\n",
    "            z_cam = get_cam_meas(transformed_frame)\n",
    "            \n",
    "            # EKF STEP\n",
    "            ekf.step(vl_cmd, vr_cmd, z_cam, r_cam=r_cam, z_mot=z_mot, r_mot=r_mot, Ts=Ts, q_proc=q_proc)\n",
    "            #print(\"ekf results:\", ekf.x, ekf.P)\n",
    "            state = ekf_get_state()\n",
    "            # motion control\n",
    "            #print(\"waypoints:\", waypoints)\n",
    "            \n",
    "            #--- LOCAL AVOIDANCE --- \n",
    "            if not(ln.prox_less_threshold(list(node[\"prox.horizontal\"][:5]), 1500)) or obstacle_not_passed :\n",
    "                print(\"here\")\n",
    "                print(list(node[\"prox.horizontal\"][:5]))\n",
    "                #print((list(node[\"prox.horizontal\"][:5]), 700))\n",
    "                objectif = (waypoints[step_count][0]/10, waypoints[step_count][1]/10) \n",
    "                curr_dir = (100*m.cos(state[2]), 100*m.sin(state[2]))\n",
    "                curr_pos = (state[0]/10, state[1]/10)\n",
    "                obstacle_not_passed = True\n",
    "                await node.wait_for_variables({\"prox.horizontal\"})\n",
    "                prox_read = list(node[\"prox.horizontal\"])\n",
    "                \n",
    "    \n",
    "                #--- TEST IF OBSTACLED IS PASSED ---\n",
    "                if (ln.prox_less_threshold(prox_read, 1000)) and obstacle_not_passed:\n",
    "                    #print(\"PASSED\")\n",
    "                    aw(control.set_motors(node,100,100))\n",
    "                    await client.sleep(1.5)\n",
    "                    obstacle_not_passed = False\n",
    "                    #if loop_count > sleep_time:  # non blocking sleep time (to get camera and filter updates)\n",
    "                    #    obstacle_not_passed = False\n",
    "                    #    loop_count = 0\n",
    "                    #loop_count += loop_count\n",
    "                    \n",
    "                    while step_count < len(waypoints) and dist_mm((state[0], state[1]), waypoints[step_count]) < thresh:\n",
    "                        #waypoints.pop(0)\n",
    "                        step_count += 1\n",
    "                    #waypoints = maybe_pop_waypoint(state, last_state, waypoints, pos_tol_mm=50.0)\n",
    "                    continue\n",
    "                \n",
    "                vect = ln.vect_calculation(objectif, (curr_pos),curr_dir,  prox_read[:5], 150, debug=False)\n",
    "                # added for global obstacles\n",
    "                # Unknown repulsion:\n",
    "                ux, uy = add_unknown_repulsion(curr_pos, unk_cells, UNKNOWN_WEIGHT=0.25, p=1.0, max_range=15.0)\n",
    "                # Combine:\n",
    "                vect = (vect[0] - ux, vect[1] - uy)\n",
    "                #\n",
    "                angle_command = m.atan2(vect[1], vect[0])\n",
    "                delta_speed = np.sign(angle_command)*min(abs(angle_command/WAIT_TIME*800/m.pi), 300)\n",
    "                left_speed = int(100+(delta_speed/2))\n",
    "                right_speed = int(100-(delta_speed/2))\n",
    "                aw(control.set_motors(node, left=left_speed, right=right_speed))\n",
    "                #print(f\" curr_pos = ({curr_pos[0]:.2f}, {curr_pos[1]:.2f}), vect = {angle_command:.2f} and delta_speed = {delta_speed:.2f}, curr_dir = ({curr_dir[0]:.2f}, {curr_dir[1]:.2f})\")\n",
    "                await client.sleep(ln.WAIT_TIME)\n",
    "                continue\n",
    "                #print(curr_dir, delta_speed*WAIT_TIME*m.pi/100, m.cos(delta_speed*WAIT_TIME*m.pi/100)\n",
    "    \n",
    "            #--- FOLLOW THE GLOBAL PATH ---\n",
    "            obstacle_not_passed = False\n",
    "            #print(\"CHECK\")\n",
    "            kidnap_first = aw(test_kidnap())\n",
    "            if kidnap_first:\n",
    "                kidnap_second = aw(test_kidnap()) # gives next waypoint to go to if kidnapped\n",
    "            if not kidnap_first and kidnap_second: # two steps on ground\n",
    "                step_count = update_kidnap(waypoints, ekf_traj)\n",
    "                kidnap_second = False\n",
    "            #print(step_count, type(step_count))\n",
    "            step_count = await control.follow_path(node, state, waypoints, step_count, v_cmd=170, kp_heading=90.0,\n",
    "                          pos_tol=12.0)\n",
    "            await client.sleep(0.1)\n",
    "            # stop when goal reached\n",
    "            if step_count >= len(waypoints):\n",
    "               stop = True\n",
    "        \n",
    "        if stop :\n",
    "            aw(node.set_variables({\"motor.left.target\":[0], \"motor.right.target\":[0]}))\n",
    "            aw(node.unlock())\n",
    "            \n",
    "    \n",
    "        # quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            aw(node.set_variables({\"motor.left.target\":[0], \"motor.right.target\":[0]}))\n",
    "            aw(node.unlock())\n",
    "            break\n",
    "    \n",
    "\n",
    "# run main\n",
    "aw(main())\n",
    "\n",
    "# Release resources\n",
    "#cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18631dec",
   "metadata": {},
   "source": [
    "![final path with camera frame, converted map frame and path plan/execution frame](pathtest.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobrob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
